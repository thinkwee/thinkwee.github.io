---
title: LLM Reasoning in 2025
date: 2025-05-30 18:09:13
categories: MyQuestion
tags:
  - inference
  - reasoning
  - llm
  - questions
refplus: true
mathjax: true
---


<img src="https://i.mji.rip/2025/07/16/bf9ca47310c9ee5c25c72925061f7d4b.png" width="500"/>

What LLM Reasoning be like in the first half of 2025.

<!--more-->

{% language_switch %}

{% lang_content en %}

- Since DeepSeek R1, researchers have been overfitting in the field of mathematical reasoning for large language models
- Clearly, every month brings new “breakthroughs” in the technology
- To boost mathematical reasoning performance by tens of points:
  - Even a model one-tenth the size can achieve it
  - A few hundred high-quality examples suffice
  - Supervised fine-tuning (SFT) can do it
  - Distillation can also do it
  - A single data point can do it
  - No data at all can do it
  - Self-generated data can do it
  - Randomly assigned rewards, or even deliberately incorrect rewards, can do it
- This teaches us not to test on the training set
- It also inspires us that if we do test on the training set, what tricks can effectively extract the already-ingested samples and produce the correct answers
- Beyond the RLVR veneer, this is also an interesting direction on how large models write in and extract knowledge
- After the first half-year carnival, which advances will stand the test of time, and which will meet a violent end?


{% endlang_content %}

{% lang_content zh %}
- 自DeepSeek R1以来，研究者们就一直在大语言模型的数学推理领域过拟合
- 肉眼可见，每个月技术都在不断“突破”
- 要提升几十点的数学推理能力
    -   十分之一大小的小模型也可以做到
    -   几百条高质量数据就可以做到
    -   SFT也可以做到
    -   蒸馏也可以做到
    -   一条数据也可以做到
    -   没有数据也可以做到
    -   自我生成数据也可以做到
    -   奖励随机设置，甚至刻意设置错误奖励也可以做到
- 这告诉我们，不要在训练集上测试
- 这也启发我们，如果在训练集上测试的话，怎样的trick才能有效提取出明明已经训进去的样本，得到正确答案
- 抛开RLVR的外壳，这也是关于大模型知识写入和提取的一个有意思的方向
- 在上半年的狂欢过后，哪些是大浪淘沙，哪些会迎来violent ends？


{% endlang_content %}

<script src="https://giscus.app/client.js"
        data-repo="thinkwee/thinkwee.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnk3OTYxNjMwOA=="
        data-category="Announcements"
        data-category-id="DIC_kwDOBL7ZNM4CkozI"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="en"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>