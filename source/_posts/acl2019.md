---
title: ACL 2019 若干论文阅读
date: 2019-07-28 09:37:46
categories: 自然语言处理
tags:
  - acl
  - machine learning
  -	natural language processing
mathjax: true
html: true
---

记录一下ACL 2019一些我感兴趣的论文的阅读笔记，先放出最佳长短论文和杰出论文，之后可能筛一些感兴趣的再读读。

<!--more-->

# Bridging the Gap between Training and Inference for Neural Machine Translation
## Background
-	最佳长论文，这个方向就很吸引人，属于很常见，大家都知道但都选择无视，或者找不出优雅有效解法的问题。
-	本文试图解决所有seq2seq都会遇到的问题，训练与推理的不一致，即exposure bias。
-	exposure bias是解码时产生的偏差。正常来讲，我们生成一句话，是从左往右逐字生成，怎么个逐字？模型生成一个字，然后这个字接着输入解码器解码出下一个字，也就是解码出每一个字时使用的上文是之前解码出的句子片段。但是这样训练收敛很慢，容易导致错误的累积。想想模型一开始本来就难以生成正确的字，现在还要基于这个错误的字生成接下来的字，那就是错上加错了。因此一般训练时，都需要使用teacher forcing的方法：forcing模型在生成每一个字的时候，依靠的是训练数据中正确的上文，也就是不管已经生成的字，只管前提正确的情况下去生成正确的字。但是这种技巧只能用于训练，测试的时候没有ground truth来teacher forcing。
-	这个问题说大不大，说小不小，之前做summarization也会遇到这个问题，导致训练的反应很好，但是测试效果差，或者出现难以解释的偏差。如今的seq2seq在编码端已经取得了长足的进步，CNN和Transformer等特征抽取器已经摆脱了单向的抽取方式，但是无论什么模型，在解码端，都得老老实实从左往右生成，都避免不了exposure bias。
-	对于翻译，exposure bias还和另一个问题打包影响了翻译的质量：逐字计算的交叉熵损失。模型需要学习到在正确的位置生成正确的词，这个双重正确的标准对于翻译来说太过苛刻，模型难以学到灵活的翻译关系，也就是over correction.
-	现有的解决exposure bias以及word-level CrossEntrophy Loss的方法有哪些？
	-	在生成词的时候，有时用ground truth，有时用自己的预测的输出，采样中庸一下，即scheduled sampling
	-	使用预训练模型，做Masked Seq2seq pretraining
	-	使用句子级别的损失函数，目标是整个句子的分数最高，而不是逐字贪心，这里包括了各种各样的优化指标以及强化学习的方法，例如mixed incremental cross-entrophy reinforce
	-	其中预训练是比较新的方法，其余两类方法早在2015年就已经提出，作者也把自己的方法与他们的方法做了对比

## Methods
-	本文想要解决以上两个问题，粗看思路还是和以前一样：通过从ground truth 和 predicted results中采样来中和偏差，以及使用句子级别的优化指标来放宽损失的约束。
-	具体怎么采样？作者给出的方法如下图（这不就是scheduled sampling的图吗。。。。）：
![e26fV1.png](https://s2.ax1x.com/2019/08/05/e26fV1.png)
	-	先选出oracle word，即模型预测的词：注意，这里用模型预测的词其实不太准确，因为模型预测的词是确定的，是decoder解码出词典概率分布取最大得到的，然而这里的oracle应该表述为not ground truth，即非真实词。假如我们直接用预测的词，那就会错上加错；假如我们用ground truth，那就会有exposure bias。因此作者取了个折中，不同于之前概率上的折中（可能取预测词可能取ground truth），还做了选词上的优化，不是简单的拿预测出的词作为oracle，具体而言：
		-	假如直接取decoder预测概率最大的词作为Oracle,那就是普通的scheduled sampling。
		-	然而作者使用Gumbel-Max正则化方法对预测概率分布调整，引入两个参数：一个由01均匀分布变量$u$计算得来的Gumbel noise $\eta$；以及一个温度变量$\gamma$。假设原始概率分布为$o$，则调整后的概率分布$P$为
		$$
			\eta = - \log ( - \log u) \\
			\overline{o} _{j-1} = (o_{j-1} + \eta) / \gamma \\
			\overline{P} _{j-1} = softmax(\overline{o} _{j-1}) \\
		$$
		-	这个加入噪音的过程只影响选择 oracle，而不影响模型的损失
	-	这是单词级别的oracle选择，还可以做句子级别的选择，具体做法是
		-	先用单词级别的方法，加上beam search，选出几个候选句
		-	通过BLEU，ROUGE等指标选出最好的句子，将这个句子的每一个词作为oracle
		-	显然这里有一个问题，就是得保证beam search出的oracle句子和ground truth的句子长度一致，作者引入了force decoding，当解码出的句子还不够ground truth长度时，假如解码出了EOS，就排除EOS，取剩下的概率最大前k个单词做beam search；假如长度已经够了，但是还没解码出EOS，就强制设置为EOS并结束解码
	-	再计算概率，决定是用oracle还是ground truth：和scheduled sampling一样，也是要设置动态采样概率，刚开始训练的时候多用ground truth，然后慢慢提高oracle的比例，作者给出的概率设置为：
	$$
	p = \frac{\mu}{\mu + exp(e / \mu)} 
	$$
-	结果当然是比naive RNN and Transformer要好，BLEU能有2个点的提升。作者也做了大量实验来测试超参数的影响。方法感觉不是很亮眼，引入Gumbel噪声的动机也没有说，但是很简单很work，尤其是引入句子层级优化的方法简单明了，比一堆目标函数的改动要直观的多。

# Do you know that Florence is packed with visitors? Evaluating state-of-the-art models of speaker commitment
-	最佳短论文，研究了一个非常有意思的方向：speaker commitment，叫说话人承诺，或者叫事件事实。这是一项自然语言理解任务，就像幽默、讽刺一样。
-	说话人承诺是指，通过说话人的描述，来判断某一事件是否发生，具体而言分三类：事实、非事实、不确定。模型需要从说话人的描述当中挖掘出事件的事实状态。传统的方法关注情态动词、动词短语，但作者引入了CommitmentBank数据集来测试各种已有模型，说明已有的数据集不能捕捉自然语言，尤其是口语当中的词法和句法多样性，且发现引入语言学知识的模型要优于LSTM，为深度学习树立了另一个有待攻克的目标。
-	举个例子来形象说明一下说话人承诺问题，“我从没相信我会研究NLP”，“我不相信我可以研究NLP”，两句话都有“相信”作为动词，且都具有否定词“从没”、“不”，那么事件是“我研究NLP”，这个事件究竟有没有发生？显然前者倾向于事件已经发生，而后者倾向于事件还未发生。还有更复杂的情形，例如给定辩论双方的陈述，猜测双方讨论的某一事实是否发生。一般而言每一条样本还会有上下文，说话人承诺任务就是给定上下文、说话人表述和事件，判断事件是否是事实。
-	作者在CommitmentBank数据集上测试了两个模型：基于规则的和基于神经网络的
	-	基于规则：Integrating Deep Linguistic Features in Factuality Prediction over Unified Datasets。 基于语言学的知识即人为给各种谓语词语/短语打上事实分数，找到谓语的隐藏签名，并根据句法树剖析来联系上形容词和情态动词，进行分数的增强或者反转，最后将各种人类知识库得分和句法结构作为特征输入SVM回归模型，计算出分数
	-	基于神经网络：Neural models of factuality。使用多层双向LSTM和tree-LSTM对句子建模，然后过一个多层MLP计算出回归分数。作者测试了双向、树、集成三种模型。
-	文章的主要部分在结果分析，数据展示很丰富，但是作者也没有给出过多的原因分析，只是在陈述哪类事实、哪类状态、哪类语料、哪类情态下哪类模型表现更好。可能是我不做这方面工作，没有感受到从这些结论里能有哪些可以挖掘的研究点。最后得出总的结论，人类知识具有更强的泛化能力，深度模型需要整合人类知识，也只是一个很泛的结论。
-	至少这篇论文得了奖，表明学界还是希望NLP研究具有多样性，像这样具有挑战性的任务并不会有太多人做，但做好之后能给下游任务例如信息抽取、对话以极大的提升。

# A Simple Theoretical Model of Importance for Summarization

# Zero-Shot Entity Linking by Reading Entity Descriptions