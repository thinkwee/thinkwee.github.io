---
title: ACL 2019 若干论文阅读
date: 2019-07-28 09:37:46
categories: 自然语言处理
tags:
  - acl
  - machine learning
  -	natural language processing
mathjax: true
html: true
---

记录一下ACL 2019一些我感兴趣的论文的阅读笔记，先放出最佳长短论文和杰出论文，之后可能筛一些感兴趣的再读读。

<!--more-->

# Bridging the Gap between Training and Inference for Neural Machine Translation
## Background
-	最佳长论文，这个方向就很吸引人，属于很常见，大家都知道但都选择无视，或者找不出优雅有效解法的问题。
-	本文试图解决所有seq2seq都会遇到的问题，训练与推理的不一致，即exposure bias。
-	exposure bias是解码时产生的偏差。正常来讲，我们生成一句话，是从左往右逐字生成，怎么个逐字？模型生成一个字，然后这个字接着输入解码器解码出下一个字，也就是解码出每一个字时使用的上文是之前解码出的句子片段。但是这样训练收敛很慢，容易导致错误的累积。想想模型一开始本来就难以生成正确的字，现在还要基于这个错误的字生成接下来的字，那就是错上加错了。因此一般训练时，都需要使用teacher forcing的方法：forcing模型在生成每一个字的时候，依靠的是训练数据中正确的上文，也就是不管已经生成的字，只管前提正确的情况下去生成正确的字。但是这种技巧只能用于训练，测试的时候没有ground truth来teacher forcing。
-	这个问题说大不大，说小不小，之前做summarization也会遇到这个问题，导致训练的反应很好，但是测试效果差，或者出现难以解释的偏差。如今的seq2seq在编码端已经取得了长足的进步，CNN和Transformer等特征抽取器已经摆脱了单向的抽取方式，但是无论什么模型，在解码端，都得老老实实从左往右生成，都避免不了exposure bias。
-	对于翻译，exposure bias还和另一个问题打包影响了翻译的质量：逐字计算的交叉熵损失。模型需要学习到在正确的位置生成正确的词，这个双重正确的标准对于翻译来说太过苛刻，模型难以学到灵活的翻译关系，也就是over correction.
-	现有的解决exposure bias以及word-level CrossEntrophy Loss的方法有哪些？
	-	在生成词的时候，有时用ground truth，有时用自己的预测的输出，采样中庸一下，即scheduled sampling
	-	使用预训练模型，做Masked Seq2seq pretraining
	-	使用句子级别的损失函数，目标是整个句子的分数最高，而不是逐字贪心，这里包括了各种各样的优化指标以及强化学习的方法，例如mixed incremental cross-entrophy reinforce
	-	其中预训练是比较新的方法，其余两类方法早在2015年就已经提出，作者也把自己的方法与他们的方法做了对比

## Methods
-	本文想要解决以上两个问题，粗看思路还是和以前一样：通过从ground truth 和 predicted results中采样来中和偏差，以及使用句子级别的优化指标来放宽损失的约束。
-	具体怎么采样？作者给出的方法如下图（这不就是scheduled sampling的图吗。。。。）：
![e26fV1.png](https://s2.ax1x.com/2019/08/05/e26fV1.png)
	-	先选出oracle word，即模型预测的词：注意，这里用模型预测的词其实不太准确，因为模型预测的词是确定的，是decoder解码出词典概率分布取最大得到的，然而这里的oracle应该表述为not ground truth，即非真实词。假如我们直接用预测的词，那就会错上加错；假如我们用ground truth，那就会有exposure bias。因此作者取了个折中，不同于之前概率上的折中（可能取预测词可能取ground truth），还做了选词上的优化，不是简单的拿预测出的词作为oracle，具体而言：
		-	假如直接取decoder预测概率最大的词作为Oracle,那就是普通的scheduled sampling。
		-	然而作者使用Gumbel-Max正则化方法对预测概率分布调整，引入两个参数：一个由01均匀分布变量$u$计算得来的Gumbel noise $\eta$；以及一个温度变量$\gamma$。假设原始概率分布为$o$，则调整后的概率分布$P$为
		$$
			\eta = - \log ( - \log u) \\
			\overline{o} _{j-1} = (o_{j-1} + \eta) / \gamma \\
			\overline{P} _{j-1} = softmax(\overline{o} _{j-1}) \\
		$$
		-	这个加入噪音的过程只影响选择 oracle，而不影响模型的损失
	-	这是单词级别的oracle选择，还可以做句子级别的选择，具体做法是
		-	先用单词级别的方法，加上beam search，选出几个候选句
		-	通过BLEU，ROUGE等指标选出最好的句子，将这个句子的每一个词作为oracle
		-	显然这里有一个问题，就是得保证beam search出的oracle句子和ground truth的句子长度一致，作者引入了force decoding，当解码出的句子还不够ground truth长度时，假如解码出了EOS，就排除EOS，取剩下的概率最大前k个单词做beam search；假如长度已经够了，但是还没解码出EOS，就强制设置为EOS并结束解码
	-	再计算概率，决定是用oracle还是ground truth：和scheduled sampling一样，也是要设置动态采样概率，刚开始训练的时候多用ground truth，然后慢慢提高oracle的比例，作者给出的概率设置为：
	$$
	p = \frac{\mu}{\mu + exp(e / \mu)} 
	$$
-	结果当然是比naive RNN and Transformer要好，BLEU能有2个点的提升。作者也做了大量实验来测试超参数的影响。方法感觉不是很亮眼，引入Gumbel噪声的动机也没有说，但是很简单很work，尤其是引入句子层级优化的方法简单明了，比一堆目标函数的改动要直观的多。

# Do you know that Florence is packed with visitors? Evaluating state-of-the-art models of speaker commitment
-	最佳短论文，研究了一个非常有意思的方向：speaker commitment，叫说话人承诺，或者叫事件事实。这是一项自然语言理解任务，就像幽默、讽刺一样。
-	说话人承诺是指，通过说话人的描述，来判断某一事件是否发生，具体而言分三类：事实、非事实、不确定。模型需要从说话人的描述当中挖掘出事件的事实状态。传统的方法关注情态动词、动词短语，但作者引入了CommitmentBank数据集来测试各种已有模型，说明已有的数据集不能捕捉自然语言，尤其是口语当中的词法和句法多样性，且发现引入语言学知识的模型要优于LSTM，为深度学习树立了另一个有待攻克的目标。
-	举个例子来形象说明一下说话人承诺问题，“我从没相信我会研究NLP”，“我不相信我可以研究NLP”，两句话都有“相信”作为动词，且都具有否定词“从没”、“不”，那么事件是“我研究NLP”，这个事件究竟有没有发生？显然前者倾向于事件已经发生，而后者倾向于事件还未发生。还有更复杂的情形，例如给定辩论双方的陈述，猜测双方讨论的某一事实是否发生。一般而言每一条样本还会有上下文，说话人承诺任务就是给定上下文、说话人表述和事件，判断事件是否是事实。
-	作者在CommitmentBank数据集上测试了两个模型：基于规则的和基于神经网络的
	-	基于规则：Integrating Deep Linguistic Features in Factuality Prediction over Unified Datasets。 基于语言学的知识即人为给各种谓语词语/短语打上事实分数，找到谓语的隐藏签名，并根据句法树剖析来联系上形容词和情态动词，进行分数的增强或者反转，最后将各种人类知识库得分和句法结构作为特征输入SVM回归模型，计算出分数
	-	基于神经网络：Neural models of factuality。使用多层双向LSTM和tree-LSTM对句子建模，然后过一个多层MLP计算出回归分数。作者测试了双向、树、集成三种模型。
-	文章的主要部分在结果分析，数据展示很丰富，但是作者也没有给出过多的原因分析，只是在陈述哪类事实、哪类状态、哪类语料、哪类情态下哪类模型表现更好。可能是我不做这方面工作，没有感受到从这些结论里能有哪些可以挖掘的研究点。最后得出总的结论，人类知识具有更强的泛化能力，深度模型需要整合人类知识，也只是一个很泛的结论。
-	至少这篇论文得了奖，表明学界还是希望NLP研究具有多样性，像这样具有挑战性的任务并不会有太多人做，但做好之后能给下游任务例如信息抽取、对话以极大的提升。

# A Simple Theoretical Model of Importance for Summarization
-	杰出论文之一，单纯是因为我也做summarization才拎出来看。作者给出了一种简单的理论模型来定量分析文摘的重要性，在此之前重要性都没有直接的、显示的定义出来。作者将语义知识融入信息熵的概念，提出了语义单元，并泛化了之前summarization一直用的三大概念：冗余度、相关性和信息性（Redundancy, Relevance and Informativeness），将这三个概念统一于重要性之下，作者还指出重要性指标与人类直接高度吻合，而不像以前的自动衡量指标一样难以保证文摘质量，
-	首先得说论文的相关工作做的很足，从上世纪50年代一直做到现在，串起了几条线，参考文献列表都值得一读。

## 定义
-	语义单元：信息的原子单位，语义单元的集合记为$\Omega$，一篇文档可以表述为在语义单元集合上的概率分布。语义单元适用于许多框架，例如frame，例如主题模型，例如深度学习常用的embedding。所有的语义单元形式都具有统一的一个特征：他们离散且独立，语言的意义基于这些语义单元产生。我们把文档和文摘标记为$D$和$S$，对应的在语义单元上的概率分布是$P_D, P_S$。
-	熵：有了概念分布就可以计算熵:$H = - \sum _{w} P(w) \log (P(w))$
-	冗余度（Redundancy）：冗余度定义为最大熵与熵之差：
	$$
	Red(S) = H_{max} - H(S)
	$$
	最大熵在均匀分布取到。实际上就是将衡量不确定性的熵转成衡量确定性的冗余度。文摘应该具有低冗余度，即熵小，否则获取的信息在文档集中大量重复，并不能带来文摘熵的减少。由于对于给定语料，最大熵是固定的，因此可以简写为$Red(S) = -H(S)$
-	相关性（Relevance）：作者如此定义相关：当我们观察文摘来推断原文的信息时，与原文真实的信息之差（损失）应该最小。既然如此我们就用这个损失的相反数来定义相关性。损失的最简单定义就是文档和文摘的语义单元分布之间的交叉熵：
$$
Rel(S,D) = - CrossEntrophy(S,D) \\
= \sum _{w_i} P_S(w_i) \log (P_D(w_i)) \\
$$
	同时我们注意到：
$$
KL(S||D) = Red(S) - Rel(S,D)
$$
-	低冗余，高相关的文摘，所带来的文摘与原文之间的KL散度最小。
-	信息性（Informativeness）：我们定义文摘的信息性为，能够改变人的常识或者知识。作者引入了背景知识$K$以及其概率分布$P_K$，并定义信息性为
$$
Inf(S,K) = CrossEntrophy(S,K)
$$
-	即高信息性应该能够带来背景知识里没有的信息。接下来就是如何定义背景知识：
	-	背景知识应该分配已知的语义单元以高概率，代表这些语义单元在用户记忆中强度很高
	-	一般来讲背景知识可以设为无，即均匀分布，但是背景知识给了Summarization一种可控的选择，即用户可以给出查询表明他们感兴趣的语义单元，那么背景知识就应该给这些语义单元低概率。
	-	在多文档摘要中，背景知识可以简化为已经生成摘要的文档
-	接下来就可以定义重要性来整合以上三种指标：**重要性应该是衡量语义单元的重要性，我们想在文摘中只保留相对重要的语义单元，这意味着我们需要找一个概率分布统一文档和背景知识，编码需要保留在文摘中的语义单元的期望**

## 重要性
-	摘要$S$应该能够从文档$D$的信息里提取出对拥有背景知识$K$的用户有用的部分，我们定义
	-	$d_i = P_D(w_i)$：语义单元$w_i$在文档中的概率
	-	$k_i = P_K(w_i)$：语义单元$w_i$在背景知识中的概率
	-	$f(d_i,k_i)$：编码语义单元重要性的函数，这个函数应该满足：
		-	信息性：$\forall i \not= j \text{if} d_i=d_j \text{and} k_i > k_j \text{then} f(d_i,k_i) < f(d_j,k_j)$
		-	相关性：$\forall i \not= j \text{if} d_i>d_j \text{and} k_i = k_j \text{then} f(d_i,k_i) > f(d_j,k_j)$
		-	可加性：$I(f(d_i,k_i)) \equiv \alpha I(d_i) + \beta I(k_i)$
		-	归一性：$\sum _i f(d_i,k_i) = 1$
	-	四条性质的公式表述很简单易懂，其中$I$是自信息。前两条说明我们想要与文档相关的，且能带来新知识的语义单元。可加性保证了与自信息定义的一致性，归一性保证这个函数是一个概率分布
-	满足以上性质的重要性编码函数为：
	$$
	P_{\frac DK}(w_i) = \frac 1C \frac {d_i^{\alpha}}{k_i^{\beta}} \\
	C = \sum _i \frac {d_i^{\alpha}}{k_i^{\beta}}, \alpha, \beta \in \mathbb{R} ^{+} \\
	$$
-	其中$\alpha$和$\beta$代表了相关性和信息性的强度
-	基于重要性的定义，我们可以找出最好的文摘应该满足：
	$$
	S^* = \text{argmax}_S \theta _I = \text{argmin} _S KL(S || P_{\frac DK})
	$$
-	因此我们取$\theta _I$作为衡量文摘质量的指标：
	$$
	\theta _I (S,D,K) = -KL(P_S||P_{\frac DK})
	$$
-	重要性概率的熵可以衡量可能的好文摘候选数量
-	衡量指标$\theta _I$其实可以拆分为之前提到的三个指标：
	$$
	\theta _I (S,D,K) \equiv -Red(S) + \alpha Rel(S,D) + \beta Inf(S,K)
	$$

## 结果
-	作者用最简单的词作为语义单元，用词频归一化作为概率分布，两个超参数$\alpha$和$\beta$均设置为1，对于增量摘要，背景知识是已经生成摘要的文档，对于普通摘要，背景知识设置为无，即均匀分布
-	结果发现重要性衡量指标比传统指标更贴近人类的判断，且更具有区分性。
-	本文作者提出的只是一个框架，背景知识、语义单元的定义可根据任务、模型灵活定义。文摘的评价问题一直缺乏好的指标，本文也算是啃了这个硬骨头，而且给出的方法简单有效。

# Zero-Shot Entity Linking by Reading Entity Descriptions