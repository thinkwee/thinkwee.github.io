---
title: ACL 2019 若干论文阅读
date: 2019-07-28 09:37:46
categories: 自然语言处理
tags:
  - acl
  - machine learning
  -	natural language processing
mathjax: true
html: true
---

记录一下ACL 2019一些我感兴趣的论文的阅读笔记，先放出最佳长短论文和杰出论文，之后可能筛一些感兴趣的再读读。

<!--more-->

# Bridging the Gap between Training and Inference for Neural Machine Translation
## Background
-	最佳长论文，这个方向就很吸引人，属于很常见，大家都知道但都选择无视，或者找不出优雅有效解法的问题。
-	本文试图解决所有seq2seq都会遇到的问题，训练与推理的不一致，即exposure bias。
-	exposure bias是解码时产生的偏差。正常来讲，我们生成一句话，是从左往右逐字生成，怎么个逐字？模型生成一个字，然后这个字接着输入解码器解码出下一个字，也就是解码出每一个字时使用的上文是之前解码出的句子片段。但是这样训练收敛很慢，容易导致错误的累积。想想模型一开始本来就难以生成正确的字，现在还要基于这个错误的字生成接下来的字，那就是错上加错了。因此一般训练时，都需要使用teacher forcing的方法：forcing模型在生成每一个字的时候，依靠的是训练数据中正确的上文，也就是不管已经生成的字，只管前提正确的情况下去生成正确的字。但是这种技巧只能用于训练，测试的时候没有ground truth来teacher forcing。
-	这个问题说大不大，说小不小，之前做summarization也会遇到这个问题，导致训练的反应很好，但是测试效果差，或者出现难以解释的偏差。如今的seq2seq在编码端已经取得了长足的进步，CNN和Transformer等特征抽取器已经摆脱了单向的抽取方式，但是无论什么模型，在解码端，都得老老实实从左往右生成，都避免不了exposure bias。
-	对于翻译，exposure bias还和另一个问题打包影响了翻译的质量：逐字计算的交叉熵损失。模型需要学习到在正确的位置生成正确的词，这个双重正确的标准对于翻译来说太过苛刻，模型难以学到灵活的翻译关系，也就是over correction.
-	现有的解决exposure bias以及word-level CrossEntrophy Loss的方法有哪些？
	-	在生成词的时候，有时用ground truth，有时用自己的预测的输出，采样中庸一下，即scheduled sampling
	-	使用预训练模型，做Masked Seq2seq pretraining
	-	使用句子级别的损失函数，目标是整个句子的分数最高，而不是逐字贪心，这里包括了各种各样的优化指标以及强化学习的方法，例如mixed incremental cross-entrophy reinforce
	-	其中预训练是比较新的方法，其余两类方法早在2015年就已经提出，作者也把自己的方法与他们的方法做了对比

## Methods
-	本文想要解决以上两个问题，粗看思路还是和以前一样：通过从ground truth 和 predicted results中采样来中和偏差，以及使用句子级别的优化指标来放宽损失的约束。
-	具体怎么采样？作者给出的方法如下图（这不就是scheduled sampling的图吗。。。。）：
![e26fV1.png](https://s2.ax1x.com/2019/08/05/e26fV1.png)
	-	先选出oracle word，即模型预测的词：注意，这里用模型预测的词其实不太准确，因为模型预测的词是确定的，是decoder解码出词典概率分布取最大得到的，然而这里的oracle应该表述为not ground truth，即非真实词。假如我们直接用预测的词，那就会错上加错；假如我们用ground truth，那就会有exposure bias。因此作者取了个折中，不同于之前概率上的折中（可能取预测词可能取ground truth），还做了选词上的优化，不是简单的拿预测出的词作为oracle，具体而言：
		-	假如直接取decoder预测概率最大的词作为Oracle,那就是普通的scheduled sampling。
		-	然而作者使用Gumbel-Max正则化方法对预测概率分布调整，引入两个参数：一个由01均匀分布变量$u$计算得来的Gumbel noise $\eta$；以及一个温度变量$\gamma$。假设原始概率分布为$o$，则调整后的概率分布$P$为
		$$
			\eta = - \log ( - \log u) \\
			\overline{o} _{j-1} = (o_{j-1} + \eta) / \gamma \\
			\overline{P} _{j-1} = softmax(\overline{o} _{j-1}) \\
		$$
		-	这个加入噪音的过程只影响选择 oracle，而不影响模型的损失
	-	这是单词级别的oracle选择，还可以做句子级别的选择，具体做法是
		-	先用单词级别的方法，加上beam search，选出几个候选句
		-	通过BLEU，ROUGE等指标选出最好的句子，将这个句子的每一个词作为oracle
		-	显然这里有一个问题，就是得保证beam search出的oracle句子和ground truth的句子长度一致，作者引入了force decoding，当解码出的句子还不够ground truth长度时，假如解码出了EOS，就排除EOS，取剩下的概率最大前k个单词做beam search；假如长度已经够了，但是还没解码出EOS，就强制设置为EOS并结束解码
	-	再计算概率，决定是用oracle还是ground truth：和scheduled sampling一样，也是要设置动态采样概率，刚开始训练的时候多用ground truth，然后慢慢提高oracle的比例，作者给出的概率设置为：
	$$
	p = \frac{\mu}{\mu + exp(e / \mu)} 
	$$
-	结果当然是比naive RNN and Transformer要好，BLEU能有2个点的提升。作者也做了大量实验来测试超参数的影响。方法感觉不是很亮眼，引入Gumbel噪声的动机也没有说，但是很简单很work，尤其是引入句子层级优化的方法简单明了，比一堆目标函数的改动要直观的多。

# Do you know that Florence is packed with visitors? Evaluating state-of-the-art models of speaker commitment

# A Simple Theoretical Model of Importance for Summarization

# Zero-Shot Entity Linking by Reading Entity Descriptions