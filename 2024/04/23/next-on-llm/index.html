<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Serif+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"thinkwee.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"duration":50,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Some very-personal questions, assumptions and predictions on the future after the large model era. I hope to keep it a habit for writing such future-ask post for every half year to keep me thinking ab">
<meta property="og:type" content="article">
<meta property="og:title" content="[Some Questions asking Myself 2024.4]">
<meta property="og:url" content="https://thinkwee.top/2024/04/23/next-on-llm/index.html">
<meta property="og:site_name" content="Thinkwee&#39;s Blog">
<meta property="og:description" content="Some very-personal questions, assumptions and predictions on the future after the large model era. I hope to keep it a habit for writing such future-ask post for every half year to keep me thinking ab">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-04-23T07:50:02.000Z">
<meta property="article:modified_time" content="2025-01-30T02:10:45.362Z">
<meta property="article:author" content="Thinkwee">
<meta property="article:tag" content="math">
<meta property="article:tag" content="inference">
<meta property="article:tag" content="seq2seq">
<meta property="article:tag" content="llm">
<meta property="article:tag" content="agent">
<meta property="article:tag" content="questions">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://thinkwee.top/2024/04/23/next-on-llm/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://thinkwee.top/2024/04/23/next-on-llm/","path":"2024/04/23/next-on-llm/","title":"[Some Questions asking Myself 2024.4]"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>[Some Questions asking Myself 2024.4] | Thinkwee's Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-96114782-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-96114782-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start --><script>(function() {function calculateHeight(element) {let height = 0;const items = element.children;for (let i = 0; i < items.length; i++) {height += items[i].offsetHeight || 25;const child = items[i].querySelector(".nav-child");if (child && child.style.display !== "none") {height += calculateHeight(child);}}return height;}function generateToc(lang, container) {const content = document.getElementById(lang + "-content");if (!content) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));if (headers.length === 0) return;const ol = document.createElement("ol");ol.className = "nav";let currentLevel = 1;let currentOl = ol;let stack = [ol];let counters = [0, 0, 0, 0, 0, 0];headers.forEach((header, index) => {const level = parseInt(header.tagName[1]);counters[level - 1]++;for (let i = level; i < 6; i++) counters[i] = 0;const li = document.createElement("li");li.className = "nav-item nav-level-" + level;if (level === 1 && index === 0) {li.classList.add("active", "active-current");}const link = document.createElement("a");link.className = "nav-link";if (level === 1 && index === 0) link.classList.add("active");link.href = "#" + header.id;const numSpan = document.createElement("span");numSpan.className = "nav-number";numSpan.textContent = counters.slice(0, level).filter(n => n > 0).join(".");const textSpan = document.createElement("span");textSpan.className = "nav-text";textSpan.textContent = header.textContent;link.appendChild(numSpan);link.appendChild(document.createTextNode(" "));link.appendChild(textSpan);li.appendChild(link);if (level > currentLevel) {const newOl = document.createElement("ol");newOl.className = "nav-child";if (currentLevel === 1) {newOl.style.display = "block";stack[currentLevel - 1].lastElementChild.classList.add("active");}stack[currentLevel - 1].lastElementChild.appendChild(newOl);stack[level - 1] = newOl;currentOl = newOl;} else if (level < currentLevel) {currentOl = stack[level - 1];}currentOl.appendChild(li);currentLevel = level;});container.appendChild(ol);setTimeout(() => {const navHeight = calculateHeight(ol);ol.style.setProperty("--height", navHeight + "px");const navChilds = ol.getElementsByClassName("nav-child");Array.from(navChilds).forEach(child => {if (child.style.display === "block") {const childHeight = calculateHeight(child);child.style.setProperty("--height", childHeight + "px");}});}, 0);return ol;}function updateActiveHeading() {const activeLang = document.getElementById("en-content").style.display === "block" ? "en" : "zh";const content = document.getElementById(activeLang + "-content");const toc = document.getElementById(activeLang + "-toc");if (!content || !toc) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));const scrollPos = window.scrollY + window.innerHeight / 3;let activeHeader = null;for (let i = headers.length - 1; i >= 0; i--) {const header = headers[i];const headerTop = header.getBoundingClientRect().top + window.scrollY;if (headerTop <= scrollPos) {activeHeader = header;break;}}const links = toc.getElementsByClassName("nav-link");Array.from(links).forEach(link => {link.classList.remove("active");const parentLi = link.parentElement;if (parentLi) {parentLi.classList.remove("active", "active-current");}});if (activeHeader) {const activeLink = toc.querySelector(`a[href="#${activeHeader.id}"]`);if (activeLink) {activeLink.classList.add("active");let parent = activeLink.parentElement;while (parent && parent.classList) {if (parent.classList.contains("nav-item")) {parent.classList.add("active");if (parent.classList.contains("nav-level-1")) {parent.classList.add("active-current");}}parent = parent.parentElement;}}}}function initTippy() {document.querySelectorAll(".refplus-num").forEach((ref) => {if (ref._tippy) {ref._tippy.destroy();}let refid = ref.firstChild.href.replace(location.origin+location.pathname,"");let refel = document.querySelector(refid);if (!refel) return;let refnum = refel.dataset.num;let ref_content = refel.innerText.replace(`[${refnum}]`,"");tippy(ref, {content: ref_content,});});}function initToc() {const originalToc = document.querySelector(".post-toc-wrap");if (!originalToc || !document.getElementById("langToggle")) return;const tocContainer = document.createElement("div");tocContainer.className = "post-toc-wrap sidebar-panel sidebar-panel-active";const enToc = document.createElement("div");enToc.id = "en-toc";enToc.className = "post-toc motion-element";enToc.style.display = "block";const zhToc = document.createElement("div");zhToc.id = "zh-toc";zhToc.className = "post-toc motion-element";zhToc.style.display = "none";generateToc("en", enToc);generateToc("zh", zhToc);tocContainer.appendChild(enToc);tocContainer.appendChild(zhToc);originalToc.parentNode.replaceChild(tocContainer, originalToc);window.addEventListener("scroll", updateActiveHeading);setTimeout(updateActiveHeading, 0);}window.toggleLanguage = function() {const enContent = document.getElementById("en-content");const zhContent = document.getElementById("zh-content");const enToc = document.getElementById("en-toc");const zhToc = document.getElementById("zh-toc");const button = document.getElementById("langToggle");if (!enContent || !zhContent || !enToc || !zhToc || !button) return;const isEnglish = enContent.style.display === "block";enContent.style.display = isEnglish ? "none" : "block";zhContent.style.display = isEnglish ? "block" : "none";enToc.style.display = isEnglish ? "none" : "block";zhToc.style.display = isEnglish ? "block" : "none";button.querySelector(".button-text").textContent = isEnglish ? "Switch to English" : "切换中文";setTimeout(updateActiveHeading, 0);setTimeout(initTippy, 100);};document.addEventListener("DOMContentLoaded", function() {initToc();setTimeout(initTippy, 3000);});})();</script><style>.post-toc { transition: all 0.2s ease-in-out; }.post-toc .nav { padding-left: 0; }.post-toc .nav-child { padding-left: 1em; }.post-toc .nav-item { line-height: 1.8; }.post-toc .nav-link { color: #555; }.post-toc .nav-link:hover { color: #222; }.post-toc .nav-link.active { color: #fc6423; }.post-toc .active > .nav-link { color: #fc6423; }.post-toc .active-current > .nav-link { color: #fc6423; }</style><!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Thinkwee's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Too Stupid to Give Up Learning</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">52</span></a></li><li class="menu-item menu-item-multi-agent-ebook"><a href="/multiagent_ebook/" rel="section"><i class="fa fa-book fa-fw"></i>Multi-Agent EBook</a></li><li class="menu-item menu-item-iagents"><a href="/iagents/" rel="section"><i class="fa fa-robot fa-fw"></i>iAgents</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#is-compression-our-only-path-to-general-intelligence"><span class="nav-number">1.</span> <span class="nav-text">Is
Compression Our Only Path to General Intelligence?</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#is-compression-all-we-need"><span class="nav-number">1.1.</span> <span class="nav-text">Is compression all we need?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#world-model-a-data-driven-approach"><span class="nav-number">1.2.</span> <span class="nav-text">World Model: A Data-Driven
Approach?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#agents"><span class="nav-number">1.3.</span> <span class="nav-text">Agents</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#alignment-and-feedback"><span class="nav-number">1.4.</span> <span class="nav-text">Alignment and Feedback</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#beyond-language"><span class="nav-number">1.5.</span> <span class="nav-text">Beyond Language</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cite-this-post"><span class="nav-number">1.6.</span> <span class="nav-text">Cite This Post</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E6%98%AF%E6%88%91%E4%BB%AC%E9%80%9A%E5%BE%80%E9%80%9A%E7%94%A8%E6%99%BA%E8%83%BD%E7%9A%84%E5%94%AF%E4%B8%80%E5%8F%AF%E8%83%BD%E5%90%97"><span class="nav-number">2.</span> <span class="nav-text">压缩是我们通往通用智能的唯一可能吗？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E8%83%BD%E8%A7%A3%E5%86%B3%E4%B8%80%E5%88%87%E5%90%97"><span class="nav-number">2.1.</span> <span class="nav-text">压缩能解决一切吗?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B%E4%BB%A5%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="nav-number">2.2.</span> <span class="nav-text">世界模型，以数据驱动的方式？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%99%BA%E8%83%BD%E4%BD%93"><span class="nav-number">2.3.</span> <span class="nav-text">智能体</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E9%BD%90%E5%8F%8D%E9%A6%88"><span class="nav-number">2.4.</span> <span class="nav-text">对齐&#x2F;反馈</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B6%85%E8%B6%8A%E8%AF%AD%E8%A8%80"><span class="nav-number">2.5.</span> <span class="nav-text">超越语言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%95%E7%94%A8"><span class="nav-number">2.6.</span> <span class="nav-text">引用</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Thinkwee</p>
  <div class="site-description" itemprop="description">Failed Better</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">59</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/thinkwee" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;thinkwee" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:thinkwee2767@gmail.com" title="E-Mail → mailto:thinkwee2767@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/thinkwee2767" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;thinkwee2767" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://scholar.google.com/citations?hl=en&user=QvW2leIAAAAJ" title="GScholar → https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl&#x3D;en&amp;user&#x3D;QvW2leIAAAAJ" rel="noopener me" target="_blank"><i class="fa fa-graduation-cap fa-fw"></i>GScholar</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="sidebar-inner sidebar-post-related">
          <div class="animated">
              <div class="links-of-blogroll-title"><i class="fa fa-signs-post fa-fw"></i>
    Related Posts
  </div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2025/05/21/next-on-llm-2/" rel="bookmark">
        <time class="popular-posts-time">2025-05-21</time>
        <br>
      [Some Questions asking Myself 2025.5]
      </a>
    </li>
  </ul>

          </div>
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://thinkwee.top/2024/04/23/next-on-llm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Thinkwee">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Thinkwee's Blog">
      <meta itemprop="description" content="Failed Better">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="[Some Questions asking Myself 2024.4] | Thinkwee's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [Some Questions asking Myself 2024.4]
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-04-23 15:50:02" itemprop="dateCreated datePublished" datetime="2024-04-23T15:50:02+08:00">2024-04-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-01-30 10:10:45" itemprop="dateModified" datetime="2025-01-30T10:10:45+08:00">2025-01-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/MyQuestion/" itemprop="url" rel="index"><span itemprop="name">MyQuestion</span></a>
        </span>
    </span>

  
    <span id="/2024/04/23/next-on-llm/" class="post-meta-item leancloud_visitors" data-flag-title="[Some Questions asking Myself 2024.4]" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>8.8k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>8 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>Some very-personal questions, assumptions and predictions on the
future after the large model era. I hope to keep it a habit for writing
such future-ask post for every half year to keep me thinking about the
"next token" in the AI era. This post is about Compression, World Model,
Agent and Alignment.</p>
<span id="more"></span>
<style>.lang-content {width: 100%;overflow: hidden;}.lang-content:not(:first-child) {display: none;}</style><div style="text-align: right; margin: 0 0 20px auto; max-width: 200px;"><button id="langToggle" onclick="toggleLanguage()" class="lang-switch-btn" style="width: 100%;padding: 10px 20px;border-radius: 8px;border: 2px solid #2c3e50;background-color: #fff;cursor: pointer;color: #2c3e50;font-size: 15px;transition: all 0.3s ease;display: flex;align-items: center;justify-content: center;gap: 8px;box-shadow: 0 2px 4px rgba(0,0,0,0.1);"><span class="button-text">切换中文</span></button></div>
<div id="en-content" class="lang-content" style="display: block;"><h1 id="is-compression-our-only-path-to-general-intelligence">Is
Compression Our Only Path to General Intelligence?</h1>
<h2 id="is-compression-all-we-need">Is compression all we need?</h2>
<ul>
<li>The first question is about compression.<br>
</li>
<li>Large models compress all the textual data in the world into the
parameters of a single model, enabling everyone to "extract" information
through natural language interaction. This process undoubtedly
alleviates knowledge or information asymmetry. For example, a dentist
can query an LLM to write code, while a programmer can enhance their
paper writing with the assistance of an LLM. Extracting pre-encoded
knowledge from LLMs is always beneficial. However, our aspirations go
beyond this simple query-based knowledge retrieval. We wonder:
<ul>
<li><strong>Can new discoveries emerge from the compressed
information/knowledge in these models?</strong> For instance, could a
physicist uncover a new law from an LLM? Or could an LLM predict the
content of this post? The answer is uncertain: it could be yes or no.
<ul>
<li>On the affirmative side, mathematicians provide an example—many
discoveries in pure theoretical research arise solely from scientists'
cognitive processes and prior knowledge. Compression-based large models
excel at leveraging past knowledge. If they can effectively simulate the
cognitive process of scientists, they might achieve groundbreaking
discoveries.<br>
</li>
<li>On the negative side, some discoveries require empirical
observation. They are "discovered" because someone observes them, such
as the identification of new species in biology, which cannot be
inferred merely from known information.<br>
</li>
<li>Another question worth pondering is whether new discoveries are even
necessary. After all, perhaps 99.999% of the world's activities in the
next second follow established patterns. A tool that efficiently
extracts and applies these patterns can still profoundly impact
humanity. While this is true, our pursuit of AGI compels us to strive
for more than this pragmatic goal.</li>
</ul></li>
<li>The core question hinges on <strong>"Is compression all we
need?"</strong><sup class="refplus-num"><a href="#ref-compression_for_agi">[1]</a></sup>
If I could compress all the world's myriad and diverse data into a
model, could it predict the future? If the model could accurately
simulate the entire world, the answer would be yes—fast-forwarding the
simulation would reveal glimpses of the future. But does compression
combined with conditional extraction truly equate to simulation?</li>
<li>Elon Musk once remarked that the focus should be on the
transformation between energy and intelligence. <strong>Is compression
the best method for such transformation?</strong> Perhaps it serves as
an efficient intermediary between energy and compressed knowledge
(instead of intelligence).<br>
</li>
<li>Related to this "compression question" is another: <strong>"Is
predicting the next token all we need?"</strong> This question probes
the limits of procedural and causal knowledge representation.</li>
</ul></li>
</ul>
<h2 id="world-model-a-data-driven-approach">World Model: A Data-Driven
Approach?</h2>
<ul>
<li>Regarding world models, a popular concept posits that intelligence
comprises several interconnected subsystems (e.g., cognition, memory,
perception, and world models), informed by human cognitive priors. The
world model specifically refers to our brain's simulation of the world,
enabling decision-making without waiting for real-world
interaction.<br>
</li>
<li>The aspiration is to model these subsystems individually. However,
most of our data is either unsupervised or end-to-end (holistic rather
than divided into subsystems). Unsupervised data poses challenges in
enabling all subsystem functionalities (e.g., language model pretraining
struggles with instruction-following). End-to-end data might not train
all subsystems effectively.<br>
</li>
<li>If we could segment and organize data to correspond to these
subsystems, could we achieve a world model in the form of multi-agent or
multi-LM systems?</li>
</ul>
<h2 id="agents">Agents</h2>
<ul>
<li><p>Could OpenAI's <em>Bitter Lesson</em> overshadow many aspects of
research on large models? Will agent-based research meet a similar fate?
In other words, even after scaling up large models, will the research
focus on agents remain irreplaceable? This might depend on whether the
most rudimentary outputs of LLMs can transition from "System 1"
(intuitive responses) to "System 2" (deliberative
reasoning)<sup class="refplus-num"><a href="#ref-system2">[2]</a></sup><sup class="refplus-num"><a href="#ref-consciousness_prior">[3]</a></sup>.</p></li>
<li><p>If an agent possesses all the actions and information of a human,
can we consider it equivalent to a human?</p></li>
</ul>
<h2 id="alignment-and-feedback">Alignment and Feedback</h2>
<ul>
<li>Everything revolves around the <strong>data flywheel</strong>. The
objective is to achieve better signals with each update by aligning the
model.<br>
</li>
<li>Alignment demonstrates the importance of improving positive samples
rather than focusing on negative samples, distinguishing it
significantly from contrastive learning.<br>
</li>
<li>Alignment<sup class="refplus-num"><a href="#ref-rlfh">[4]</a></sup>
can be beneficial or detrimental, depending on the goal to which the
model is aligned.<br>
</li>
<li>Some interesting questions are:
<ul>
<li>How can we integrate various forms of feedback (human/non-human,
textual/other modalities, social/physical)?<br>
</li>
<li>By connecting all these feedback types, we might align models with
more powerful goals. Moreover, the laws governing this integration could
reveal fundamental rules of the world.<br>
</li>
<li>Reward models exemplify the energy hidden in tradeoffs: by
sacrificing some precision, we gain scalable training, rewarding, and
labeling. This tradeoff results in stable improvements. Can we uncover
more such "energy" within these processes?
<ul>
<li>For example, could cascading reward models (like interlocking gears)
amplify the reward knowledge encoded by human annotations across
datasets?<br>
</li>
</ul></li>
<li>Similarly, the <strong>alignment
tax</strong><sup class="refplus-num"><a href="#ref-alignment_tax">[5]</a></sup>
represents another tradeoff. Is there latent "energy" in these
tradeoffs, where sacrificing A for B leads to overall intelligence
gains?</li>
</ul></li>
</ul>
<h2 id="beyond-language">Beyond Language</h2>
<ul>
<li>Language is more intricate, reasoned, and abstract than other
modalities because it is fundamentally "unnatural"—a construct of human
invention.<br>
</li>
<li>Nonetheless, researchers have identified an elegant objective for
language: <strong>predicting the next token</strong>, a goal reflecting
the entire history of computational linguistics.<br>
</li>
<li>Other modalities, like images, videos, and sounds, are "natural," as
they convey raw information from the physical world. Could these
modalities have objectives as intuitive or powerful as predicting the
next token?<br>
</li>
<li>What implications do multimodal capabilities have for the reasoning
abilities of large models?</li>
</ul>
<h2 id="cite-this-post">Cite This Post</h2>
<p>If you find this post helpful or interesting, you can cite it as:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@article{next_on_llm_2024,</span><br><span class="line">  author = {Wei Liu},</span><br><span class="line">  title = {[Some Questions asking Myself 2024.4] Compression, World Model, Agent and Alignment},</span><br><span class="line">  year = {2024},</span><br><span class="line">  month = {4},</span><br><span class="line">  url = {https://thinkwee.top/2024/04/23/next-on-llm/#more},</span><br><span class="line">  note = {Blog post}</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
</div>
<div id="zh-content" class="lang-content" style="display: none;"><h1 id="压缩是我们通往通用智能的唯一可能吗">压缩是我们通往通用智能的唯一可能吗？</h1>
<h2 id="压缩能解决一切吗">压缩能解决一切吗?</h2>
<ul>
<li>这是第一个问题，关于压缩。</li>
<li>大模型将世界上所有的的语料压缩到一个模型的参数中，每个人都可以通过自然语言交互来"提取"信息。这个过程无疑缓解了信息或知识的不对称性。例如，一个牙医可以通过查询LLM来编写程序，而程序员也可以通过LLM的协助来提升工作效率。从LLM中提取已编码的现有知识总是有益的，但我们想要肯定不仅仅是这种简单的知识查询，而是更多的可能：
<ul>
<li>是否可能用现有的压缩信息/知识发现新事物？例如，物理学家能否从LLM中发现新定律？或者LLM能否预测这篇文章？目前没有答案，可能是，也可能不是。
<ul>
<li>积极的一面是，数学家已经证明了这一点，因为许多纯理论研究发现仅源于科学家的大脑和过去的知识。基于压缩的大模型擅长利用过去的知识，如果它们能有效地模拟科学家的认知过程，就可能发现新的发现。</li>
<li>消极的一面是，一些新发现往往来自经验观察（他们"发现"某物是因为他们看到了它），比如在生物学中，新的物种不可能仅仅从已知物种信息的推理中得出。</li>
</ul></li>
<li>另一个值得思考的问题是，新的发现是否真的必要。可能下一秒钟的世界，99.999%的活动都遵循着既定模式。一个能够高效提取和应用这些模式的工具仍然可以深刻影响人类。即便如此，我们追求
AGI（通用人工智能）的理想肯定远大于仅仅挖掘实用模式。</li>
<li>核心问题在于“压缩是否就是我们需要的全部？”<sup class="refplus-num"><a href="#ref-compression_for_agi">[1]</a></sup>如果我能将世界上千变万化的数据压缩进一个模型，它能否预测未来？如果模型能够准确模拟整个世界，答案就是肯定的——快进模拟将揭示未来的片段。但是，压缩与条件提取的结合真的等同于模拟吗？</li>
<li>埃隆·马斯克曾表示，应关注能量与智能之间的转化。压缩是否是这种转化的最佳方法？或许它充当了能量与压缩知识之间的高效中介，而不是能量与智能的中介。</li>
<li>与此“压缩问题”相关的是另一个问题：“预测下一个标记是否就是我们需要的全部？”这个问题探讨了程序和因果知识表示的极限。</li>
</ul></li>
</ul>
<h2 id="世界模型以数据驱动的方式">世界模型，以数据驱动的方式？</h2>
<ul>
<li>对于世界模型，一种流行的说法是基于人类认知的先验将智能分割成几个相互连接的子系统（包含认知/记忆/感知/世界模型）。世界模型包含了我们脑中对于世界的模拟，这样我们不用等到与真实世界交互之后再进行决策。</li>
<li>我们期望用模型分别建模这几个子系统，但我们拥有的大多数数据都是无监督的或端到端的（整体而不是分成多个子部分的数据），而无监督的建模难以实现所有部分的功能（例如预训练阶段的语言模型无法实现指令跟随），端到端的数据则不确定能否训练好所有子系统。</li>
<li>如果数据可以为所有这些子系统分割和组织，我们能否以多智能体或多LM系统的形式实现世界模型？</li>
</ul>
<h2 id="智能体">智能体</h2>
<ul>
<li>OpenAI的"痛苦教训"可能会掩盖许多关于大模型的研究。智能体是否会面临类似的命运？</li>
<li>换句话说，即使在扩大大模型规模后，智能体研究的内容是否仍然不可为LLM所替代？这可能取决于LLM最朴素的响应是否能从系统1过渡到系统2<sup class="refplus-num"><a href="#ref-system2">[2]</a></sup><sup class="refplus-num"><a href="#ref-consciousness_prior">[3]</a></sup>。</li>
<li>如果一个智能体拥有一个人的所有行为和信息，我们能说它就是一个人吗？</li>
</ul>
<h2 id="对齐反馈">对齐/反馈</h2>
<ul>
<li>一切都与数据飞轮有关。目标是在每次更新中对齐模型后获得更好的信号。</li>
<li>对齐<sup class="refplus-num"><a href="#ref-rlfh">[4]</a></sup>证明我们需要更好的正样本，而不是构建负样本。这是与对比学习的一个显著区别。</li>
<li>对齐可以是好的也可以是坏的，这取决于模型对齐的目标。</li>
<li>我们如何连接各种反馈，包括人类/非人类、文本/其他模态、人类社会/物理世界。</li>
<li>通过链接所有这些反馈我们可以与更强大的目标对齐。更重要的是，连接这些反馈的规律可能揭示世界的规则。</li>
<li>RLFH使用人类标注训练奖励模型，然后用奖励模型扩大规模训练语言模型，实现了人类标注和模型标注的tradeoff，牺牲了一点奖励的精确度，换来了奖励样本的scale
up。RLFH挖掘了这种tradeoff中蕴含着的能量，即牺牲多少质量，换来多少数量，可以带来最终效果的稳定提升。我们是否可能挖掘更多这种能量的可能性？比如级联的reward
model，例如齿轮一般，将人类标注的奖励知识不断放大到样本中。</li>
<li>类似的，alignment
tax<sup class="refplus-num"><a href="#ref-alignment_tax">[5]</a></sup>也是一种tradeoff，这种tradeoff是否也有牺牲A换来B但最终提升了整体智能的能量？</li>
</ul>
<h2 id="超越语言">超越语言</h2>
<ul>
<li>语言比其他模态更复杂、更具推理性、更抽象，因为它实际上是"非自然的"，是人类创造的。</li>
<li>但研究人员为语言找到了一个令人惊叹的目标，它反映了计算语言学的整个历史，即语言模型，也就是预测下一个词。</li>
<li>图像/视频/声音等其他模态是自然的，因为它们传达了物理世界的原始信息。这些信息能否有类似或更朴素的目标？</li>
<li>更多模态对大模型的推理能力意味着什么？</li>
</ul>
<h2 id="引用">引用</h2>
<p>如果你觉得这篇博文的话题很有趣，需要引用时，可以使用如下bibtex:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@article{next_on_llm_2024_4,</span><br><span class="line">  author = {Wei Liu},</span><br><span class="line">  title = {[Some Questions asking Myself 2024.4] Compression, World Model, Agent and Alignment},</span><br><span class="line">  year = {2024},</span><br><span class="line">  month = {4},</span><br><span class="line">  url = {https://thinkwee.top/2024/04/23/next-on-llm/#more},</span><br><span class="line">  note = {Blog post}</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
</div>
<script src="https://giscus.app/client.js" data-repo="thinkwee/thinkwee.github.io" data-repo-id="MDEwOlJlcG9zaXRvcnk3OTYxNjMwOA==" data-category="Announcements" data-category-id="DIC_kwDOBL7ZNM4CkozI" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" data-loading="lazy" crossorigin="anonymous" async>
</script>
<ul id="refplus"><li id="ref-compression_for_agi" data-num="1">[1]  Compression for AGI - Jack Rae | Stanford MLSys #76 https://www.youtube.com/watch?v=dO4TPJkeaaU</li><li id="ref-system2" data-num="2">[2]  LeCun, Y. (2022). A path towards autonomous machine intelligence. version 0.9. 2, 2022-06-27. Open Review, 62(1), 1-62.</li><li id="ref-consciousness_prior" data-num="3">[3]  Bengio, Y. (2017). The consciousness prior. arXiv preprint arXiv:1709.08568.</li><li id="ref-rlfh" data-num="4">[4]  Christiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., &amp; Amodei, D. (2017). Deep reinforcement learning from human preferences. Advances in neural information processing systems, 30.</li><li id="ref-alignment_tax" data-num="5">[5]  Askell, A., Bai, Y., Chen, A., Drain, D., Ganguli, D., Henighan, T., ... &amp; Kaplan, J. (2021). A general language assistant as a laboratory for alignment. arXiv preprint arXiv:2112.00861.</li></ul>

    <style>
    #refplus, #refplus li{ 
        padding:0;
        margin:0;
        list-style:none;
    }；
    </style>
    <script src="https://unpkg.com/@popperjs/core@2"></script>
    <script src="https://unpkg.com/tippy.js@6"></script>
    <script>
    document.querySelectorAll(".refplus-num").forEach((ref) => {
        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');
        let refel = document.querySelector(refid);
        let refnum = refel.dataset.num;
        let ref_content = refel.innerText.replace(`[${refnum}]`,'');
        tippy(ref, {
            content: ref_content,
        });
    });
    </script>
    
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/math/" rel="tag"># math</a>
              <a href="/tags/inference/" rel="tag"># inference</a>
              <a href="/tags/seq2seq/" rel="tag"># seq2seq</a>
              <a href="/tags/llm/" rel="tag"># llm</a>
              <a href="/tags/agent/" rel="tag"># agent</a>
              <a href="/tags/questions/" rel="tag"># questions</a>
          </div>

        
  <div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style">
    <a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a>
      <a class="a2a_button_facebook"></a>
      <a class="a2a_button_twitter"></a>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/07/20/marl/" rel="prev" title="Multi-agent Reinforcement Learning Notes">
                  <i class="fa fa-angle-left"></i> Multi-agent Reinforcement Learning Notes
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/05/21/next-on-llm-2/" rel="next" title="[Some Questions asking Myself 2025.5]">
                  [Some Questions asking Myself 2025.5] <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">ICP/IP地址/域名信息备案管理系统 </a>
      <img src="http://www.beian.gov.cn/img/new/gongan.png" alt=""><a href="https://beian.mps.gov.cn/#/query/webSearch?code=%E4%BA%ACICP%E5%A4%872023015408%E5%8F%B7" rel="noopener" target="_blank">京ICP备2023015408号 </a>
  </div>
  <div class="copyright">
    &copy; 2017 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Thinkwee</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">1.1m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">16:51</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/thinkwee" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.0/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>





  <script src="/js/third-party/addtoany.js"></script>

  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"g58NgfMJBlwTyftr6hizdozq-gzGzoHsz","app_key":"1nA1tNVxeeSlAumHogP0PvSd","server_url":null,"security":true}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://thinkwee.top/2024/04/23/next-on-llm/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
