<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Serif+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"thinkwee.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"duration":50,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Introduction of the Lagrange multiplier method and its extension KKT conditions, as well as their applications in PCA and SVM">
<meta property="og:type" content="article">
<meta property="og:title" content="Lagrange,KKT,PCA,SVM">
<meta property="og:url" content="https://thinkwee.top/2017/03/18/Lagrange/index.html">
<meta property="og:site_name" content="Thinkwee&#39;s Blog">
<meta property="og:description" content="Introduction of the Lagrange multiplier method and its extension KKT conditions, as well as their applications in PCA and SVM">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.mji.rip/2025/07/16/681b34e5ff4f1b7bf5780a5eb7a984ce.png">
<meta property="og:image" content="https://s1.ax1x.com/2018/10/20/i0olwj.png">
<meta property="article:published_time" content="2017-03-18T03:20:35.000Z">
<meta property="article:modified_time" content="2025-07-16T10:42:05.826Z">
<meta property="article:author" content="Thinkwee">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="code">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.mji.rip/2025/07/16/681b34e5ff4f1b7bf5780a5eb7a984ce.png">


<link rel="canonical" href="https://thinkwee.top/2017/03/18/Lagrange/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://thinkwee.top/2017/03/18/Lagrange/","path":"2017/03/18/Lagrange/","title":"Lagrange,KKT,PCA,SVM"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Lagrange,KKT,PCA,SVM | Thinkwee's Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-96114782-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-96114782-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start --><script>(function() {function calculateHeight(element) {let height = 0;const items = element.children;for (let i = 0; i < items.length; i++) {height += items[i].offsetHeight || 25;const child = items[i].querySelector(".nav-child");if (child && child.style.display !== "none") {height += calculateHeight(child);}}return height;}function generateToc(lang, container) {const content = document.getElementById(lang + "-content");if (!content) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));if (headers.length === 0) return;const ol = document.createElement("ol");ol.className = "nav";let currentLevel = 1;let currentOl = ol;let stack = [ol];let counters = [0, 0, 0, 0, 0, 0];headers.forEach((header, index) => {const level = parseInt(header.tagName[1]);counters[level - 1]++;for (let i = level; i < 6; i++) counters[i] = 0;const li = document.createElement("li");li.className = "nav-item nav-level-" + level;if (level === 1 && index === 0) {li.classList.add("active", "active-current");}const link = document.createElement("a");link.className = "nav-link";if (level === 1 && index === 0) link.classList.add("active");link.href = "#" + header.id;const numSpan = document.createElement("span");numSpan.className = "nav-number";numSpan.textContent = counters.slice(0, level).filter(n => n > 0).join(".");const textSpan = document.createElement("span");textSpan.className = "nav-text";textSpan.textContent = header.textContent;link.appendChild(numSpan);link.appendChild(document.createTextNode(" "));link.appendChild(textSpan);li.appendChild(link);if (level > currentLevel) {const newOl = document.createElement("ol");newOl.className = "nav-child";if (currentLevel === 1) {newOl.style.display = "block";stack[currentLevel - 1].lastElementChild.classList.add("active");}stack[currentLevel - 1].lastElementChild.appendChild(newOl);stack[level - 1] = newOl;currentOl = newOl;} else if (level < currentLevel) {currentOl = stack[level - 1];}currentOl.appendChild(li);currentLevel = level;});container.appendChild(ol);setTimeout(() => {const navHeight = calculateHeight(ol);ol.style.setProperty("--height", navHeight + "px");const navChilds = ol.getElementsByClassName("nav-child");Array.from(navChilds).forEach(child => {if (child.style.display === "block") {const childHeight = calculateHeight(child);child.style.setProperty("--height", childHeight + "px");}});}, 0);return ol;}function updateActiveHeading() {const activeLang = document.getElementById("en-content").style.display === "block" ? "en" : "zh";const content = document.getElementById(activeLang + "-content");const toc = document.getElementById(activeLang + "-toc");if (!content || !toc) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));const scrollPos = window.scrollY + window.innerHeight / 3;let activeHeader = null;for (let i = headers.length - 1; i >= 0; i--) {const header = headers[i];const headerTop = header.getBoundingClientRect().top + window.scrollY;if (headerTop <= scrollPos) {activeHeader = header;break;}}const links = toc.getElementsByClassName("nav-link");Array.from(links).forEach(link => {link.classList.remove("active");const parentLi = link.parentElement;if (parentLi) {parentLi.classList.remove("active", "active-current");}});if (activeHeader) {const activeLink = toc.querySelector(`a[href="#${activeHeader.id}"]`);if (activeLink) {activeLink.classList.add("active");let parent = activeLink.parentElement;while (parent && parent.classList) {if (parent.classList.contains("nav-item")) {parent.classList.add("active");if (parent.classList.contains("nav-level-1")) {parent.classList.add("active-current");}}parent = parent.parentElement;}}}}function initTippy() {document.querySelectorAll(".refplus-num").forEach((ref) => {if (ref._tippy) {ref._tippy.destroy();}let refid = ref.firstChild.href.replace(location.origin+location.pathname,"");let refel = document.querySelector(refid);if (!refel) return;let refnum = refel.dataset.num;let ref_content = refel.innerText.replace(`[${refnum}]`,"");tippy(ref, {content: ref_content,});});}function initToc() {const originalToc = document.querySelector(".post-toc-wrap");if (!originalToc || !document.getElementById("langToggle")) return;const tocContainer = document.createElement("div");tocContainer.className = "post-toc-wrap sidebar-panel sidebar-panel-active";const enToc = document.createElement("div");enToc.id = "en-toc";enToc.className = "post-toc motion-element";enToc.style.display = "block";const zhToc = document.createElement("div");zhToc.id = "zh-toc";zhToc.className = "post-toc motion-element";zhToc.style.display = "none";generateToc("en", enToc);generateToc("zh", zhToc);tocContainer.appendChild(enToc);tocContainer.appendChild(zhToc);originalToc.parentNode.replaceChild(tocContainer, originalToc);window.addEventListener("scroll", updateActiveHeading);setTimeout(updateActiveHeading, 0);}window.toggleLanguage = function() {const enContent = document.getElementById("en-content");const zhContent = document.getElementById("zh-content");const enToc = document.getElementById("en-toc");const zhToc = document.getElementById("zh-toc");const button = document.getElementById("langToggle");if (!enContent || !zhContent || !enToc || !zhToc || !button) return;const isEnglish = enContent.style.display === "block";enContent.style.display = isEnglish ? "none" : "block";zhContent.style.display = isEnglish ? "block" : "none";enToc.style.display = isEnglish ? "none" : "block";zhToc.style.display = isEnglish ? "block" : "none";button.querySelector(".button-text").textContent = isEnglish ? "Switch to English" : "切换中文";setTimeout(updateActiveHeading, 0);setTimeout(initTippy, 100);};document.addEventListener("DOMContentLoaded", function() {initToc();setTimeout(initTippy, 3000);});})();</script><style>.post-toc { transition: all 0.2s ease-in-out; }.post-toc .nav { padding-left: 0; }.post-toc .nav-child { padding-left: 1em; }.post-toc .nav-item { line-height: 1.8; }.post-toc .nav-link { color: #555; }.post-toc .nav-link:hover { color: #222; }.post-toc .nav-link.active { color: #fc6423; }.post-toc .active > .nav-link { color: #fc6423; }.post-toc .active-current > .nav-link { color: #fc6423; }</style><!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Thinkwee's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Too Stupid to Give Up Learning</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">51</span></a></li><li class="menu-item menu-item-multi-agent-ebook"><a href="/multiagent_ebook/" rel="section"><i class="fa fa-book fa-fw"></i>Multi-Agent EBook</a></li><li class="menu-item menu-item-iagents"><a href="/iagents/" rel="section"><i class="fa fa-robot fa-fw"></i>iAgents</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#lagrange-multiplier-method"><span class="nav-number">1.</span> <span class="nav-text">Lagrange multiplier method</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#carroll-kuhn-tucker-condition"><span class="nav-number">2.</span> <span class="nav-text">Carroll-Kuhn-Tucker
condition</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#pca"><span class="nav-number">3.</span> <span class="nav-text">PCA</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#pca-using-covariance-matrix"><span class="nav-number">4.</span> <span class="nav-text">PCA using Covariance Matrix</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#support-vector-machine"><span class="nav-number">5.</span> <span class="nav-text">Support Vector Machine</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95"><span class="nav-number">6.</span> <span class="nav-text">拉格朗日乘子法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8D%A1%E7%BD%97%E9%9C%80-%E5%BA%93%E6%81%A9-%E5%A1%94%E5%85%8B%E6%9D%A1%E4%BB%B6"><span class="nav-number">7.</span> <span class="nav-text">卡罗需-库恩-塔克条件</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#pca"><span class="nav-number">8.</span> <span class="nav-text">PCA</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#pca-using-covariance-matrix"><span class="nav-number">9.</span> <span class="nav-text">PCA using Covariance Matrix</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#svm"><span class="nav-number">10.</span> <span class="nav-text">SVM</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Thinkwee</p>
  <div class="site-description" itemprop="description">Failed Better</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">51</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">61</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/thinkwee" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;thinkwee" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:thinkwee2767@gmail.com" title="E-Mail → mailto:thinkwee2767@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/thinkwee2767" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;thinkwee2767" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://scholar.google.com/citations?hl=en&user=QvW2leIAAAAJ" title="GScholar → https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl&#x3D;en&amp;user&#x3D;QvW2leIAAAAJ" rel="noopener me" target="_blank"><i class="fa fa-graduation-cap fa-fw"></i>GScholar</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://thinkwee.top/2017/03/18/Lagrange/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Thinkwee">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Thinkwee's Blog">
      <meta itemprop="description" content="Failed Better">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Lagrange,KKT,PCA,SVM | Thinkwee's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Lagrange,KKT,PCA,SVM
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-18 11:20:35" itemprop="dateCreated datePublished" datetime="2017-03-18T11:20:35+08:00">2017-03-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-16 18:42:05" itemprop="dateModified" datetime="2025-07-16T18:42:05+08:00">2025-07-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
    </span>

  
    <span id="/2017/03/18/Lagrange/" class="post-meta-item leancloud_visitors" data-flag-title="Lagrange,KKT,PCA,SVM" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>10 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><img data-src="https://i.mji.rip/2025/07/16/681b34e5ff4f1b7bf5780a5eb7a984ce.png" width="500"/></p>
<p>Introduction of the Lagrange multiplier method and its extension KKT
conditions, as well as their applications in PCA and SVM</p>
<span id="more"></span>
<p><img data-src="https://s1.ax1x.com/2018/10/20/i0olwj.png"
alt="i0olwj.png" /> Image from Wikipedia's illustrative introduction to
the Lagrange multiplier method</p>
<style>.lang-content {width: 100%;overflow: hidden;}.lang-content:not(:first-child) {display: none;}</style><div style="text-align: right; margin: 0 0 20px auto; max-width: 200px;"><button id="langToggle" onclick="toggleLanguage()" class="lang-switch-btn" style="width: 100%;padding: 10px 20px;border-radius: 8px;border: 2px solid #2c3e50;background-color: #fff;cursor: pointer;color: #2c3e50;font-size: 15px;transition: all 0.3s ease;display: flex;align-items: center;justify-content: center;gap: 8px;box-shadow: 0 2px 4px rgba(0,0,0,0.1);"><span class="button-text">切换中文</span></button></div>
<div id="en-content" class="lang-content" style="display: block;"><h1 id="lagrange-multiplier-method">Lagrange multiplier method</h1>
<ul>
<li><p>Lagrange multiplier method is a method for finding extrema under
constraints, described as</p>
<p><span class="math display">\[
under the constraint condition g(x,y)=c \\
find the extremum of f(x,y) \\
\]</span></p>
<p>The main idea is to synthesize the constraint conditions and the
original function into a single function, convert it into an
unconstrained condition, and then find the partial derivatives to obtain
the extremum.</p></li>
<li><p>It can be seen from the figure that points with equal values of
the function f can form blue rings similar to contour lines, with the
constraint conditions represented by the green path. The problem can be
transformed into finding the point along the green path where the blue
ring associated with that point is either closest to the center or
farthest from the center (maximum or minimum value).</p></li>
<li><p>Clearly, the point of tangency between the green path and the
blue loop attains an extremum, at which their gradients (arrows) are
parallel, described as</p>
<p><span class="math display">\[
\nabla f (x, y) = \nabla (\lambda \left(g \left(x, y \right) - c
\right))
\]</span></p>
<p><span class="math inline">\(\lambda\)</span> is the Lagrange
multiplier, representing the size multiple of the two parallel gradients
in this formula, with the sign indicating that the two gradients are in
opposite directions. The Lagrange multiplier is not equal to 0. The
Lagrange equation is given by <span class="math inline">\(F(x,y)=\nabla
\Big[f \left(x, y \right) + \lambda \left(g \left(x, y \right) - c
\right) \Big]\)</span></p></li>
<li><p>Solving the above equation yields a set of <span
class="math inline">\((x,y,\lambda)\)</span> , which are the critical
points and the Lagrange multipliers at the points of extremum. At this
time, the Lagrange equations <span
class="math inline">\(F(x,y)=f(x,y)\)</span> hold, because when the
extremum is achieved, the constraint condition part must be 0 (we are
moving along the constraint condition to find the tangent points, and
the tangent points are on the constraint path).</p></li>
<li><p>Lagrange coefficients refer to the maximum growth value, <span
class="math inline">\(-\frac{\partial \Lambda}{\partial {c_k}} =
\lambda_k\)</span></p></li>
</ul>
<h1 id="carroll-kuhn-tucker-condition">Carroll-Kuhn-Tucker
condition</h1>
<ul>
<li><p>If the constraint conditions are not only equations but also
include inequality constraints, it is necessary to generalize the
Lagrange multiplier method to the KKT conditions</p></li>
<li><p>The problem of optimization with inequality constraints is
described as</p>
<p><span class="math display">\[
under the constraint condition: \\
h_j(X)=0 j=1,2,...,p \\
g_k(X)\leq 0 k=1,2,...q \\
find the extremum of f(X) \\
\]</span></p></li>
<li><p>Lagrange function is</p>
<p><span class="math display">\[
L(X,\lambda ,\mu)=f(X)+\sum _{j=1}^p \lambda _j h_j(X) + \sum _{k=1}^q
\mu g_k(X)
\]</span></p></li>
<li><p>KKT conditions are given by:</p>
<p><span class="math display">\[
\frac{dL}{dX}=0 \\
\lambda _j \neq 0 \\
\mu _k \geq 0 \\
\mu _k g_k(X)=0 \\
h_j(X)=0 \\
g_k(X) \leq 0\\
\]</span></p></li>
</ul>
<h1 id="pca">PCA</h1>
<ul>
<li><p>PCA stands for Principal Component Analysis, which optimizes the
original dimensions of the data to form a set of new dimensions. These
new dimensions are linear combinations of the original dimensions and
are mutually independent. They are sorted by importance, with one
dimension being understood as a column in a data matrix, where each row
represents a sample</p></li>
<li><p><span class="math inline">\(x_1,...,x_p\)</span> represents the
original p dimensions, and the new dimensions are <span
class="math inline">\(\xi _1,....,\xi _p\)</span></p></li>
<li><p>New dimensions are linear combinations of the original
dimensions, represented as</p>
<p><span class="math display">\[
\xi _i = \sum _{j=1}^{p}  \alpha _{ij} x_j = \alpha _i^T x
\]</span></p></li>
<li><p>In order to unify the scales across all new dimensions, the
vector length of the coefficients of the linear combination of each new
dimension is set to 1, i.e.,</p>
<p><span class="math display">\[
\alpha _i^T \alpha _i=1
\]</span></p></li>
<li><p>Let A be the feature transformation matrix, composed of the
coefficient vectors of the linear combinations of the new dimensions,
then it is necessary to solve for an optimal orthogonal transformation A
such that the variance of the new dimensions reaches an extremum. An
orthogonal transformation ensures that the new dimensions are
uncorrelated; the greater the variance, the more distinct the samples
are in the new dimensions, which facilitates our data
classification.</p></li>
<li><p>The problem is then transformed into an optimization problem with
constraints, where the constraint is <span class="math inline">\(\alpha
_i^T \alpha _i=1\)</span> , and the extremum of <span
class="math inline">\(var(\xi _i)\)</span> is to be found, which can be
solved using the Lagrange multiplier method</p></li>
<li><p>When i=1, we obtain the first new dimension, which is also the
most important (with the largest variance), and then set i=2, adding the
constraint condition <span class="math inline">\(E[\xi _2 \xi _1\-E[\xi
_1][\xi _2]]=0\)</span> , that is, the two new dimensions are
uncorrelated, and obtain the second new dimension</p></li>
<li><p>Sequentially determine p new dimensions</p></li>
<li><p>PCA can optimize the original data, identify dimensions with
discriminative power, and more importantly, if there are correlations
among the dimensions of the original data, PCA can eliminate these
correlations. Even if the correlations in the original data are low, if
we only take the first k (k &lt; q) new dimensions, we can perform
dimensionality reduction with minimal loss of precision, greatly
shortening the training time of the data</p></li>
<li><p>If we take the first k new dimensions and perform the inverse
operation of PCA on them, we can achieve data denoising, because the new
dimensions with very low importance generally reflect the random noise
in the data. By discarding them and restoring the original data, we
achieve the removal of noise</p></li>
<li><p>PCA is unsupervised, does not consider the category or label of
the samples themselves, and is not necessarily the optimal solution in
supervised learning; feature extraction for classification objectives
can be achieved using the K-L transform</p></li>
</ul>
<h1 id="pca-using-covariance-matrix">PCA using Covariance Matrix</h1>
<ul>
<li>The above method for solving PCA is too complicated; it can be
solved through the covariance matrix in practice (because there are
efficient matrix eigenvalue decomposition algorithms)</li>
<li>The optimization objective of PCA is to reselect a set of bases
(features) such that the covariance between different features is 0
under the representation of this set of bases, and the variance within
the same feature is maximized</li>
<li>The problem can be restated as, for the data tensor X,
zero-centering by feature columns (a total of m features) (simplifying
the calculation of covariance), calculate the covariance matrix <span
class="math inline">\(C=\frac 1m X^T X\)</span> . It is hoped to find a
set of bases P such that the covariance matrix D of the transformed data
<span class="math inline">\(Y=PX\)</span> is diagonal, with non-diagonal
elements (covariances) equal to 0. If the diagonal elements (variances)
are arranged from large to small, then taking the first k rows of the P
matrix can reduce the feature dimension from m to k. It is easy to
obtain <span class="math inline">\(D=PCP^T\)</span> , and since C is a
real symmetric matrix, the problem then transforms into diagonalizing
the real symmetric matrix C, and the new set of bases we need are the
eigenvector set.</li>
<li>Algorithm:
<ul>
<li><p>There are m sets of n-dimensional data arranged into a matrix X
with n rows and m columns</p></li>
<li><p>Zero-mean normalization of each row of X</p></li>
<li><p>Determine the covariance matrix C</p></li>
<li><p>Determine the eigenvalues and eigenvectors of the covariance
matrix</p></li>
<li><p>Arrange the feature vectors according to the size of their
eigenvalues from largest to smallest in rows, forming a new basis matrix
P</p></li>
<li><p>If necessary, take the first k rows of P, and the
reduced-dimensional data is <span
class="math inline">\(Y=PX\)</span></p>
<pre><code>def PCA(X, dims):
m = len(X)
mean = np.mean(X, axis=0)
X = X - mean
C = np.dot(X.T, X) / m
Eigen_Value, Eigen_Vector = np.linalg.eig(C)
index = np.argsort(Eigen_Value)[-1:-dims - 1:-1]
PCA_Vector = Eigen_Vector[index]
X_PCA = np.dot(PCA_Vector, X.T)
return X_PCA.T</code></pre></li>
</ul></li>
</ul>
<h1 id="support-vector-machine">Support Vector Machine</h1>
<ul>
<li><p>In classification learning, we need to find a separating
hyperplane that separates samples of different categories, and the best
separating hyperplane is obviously one that is as far away as possible
from the samples of each category, i.e., the hyperplane with the best
tolerance to local perturbations of the training samples</p></li>
<li><p>The hyperplane is described by the equation <span
class="math inline">\(w^Tx+b=0\)</span> , where w is the normal vector
determining the direction of the hyperplane, and b is the displacement
of the hyperplane to the far point</p></li>
<li><p>Solving an SVM, i.e., finding a solution that satisfies the
constraints</p>
<p><span class="math display">\[
\begin{cases}
w^Tx_i+b \geq +1, y_i=+1 \\
w^Tx_i+b \leq -1, y_i=-1 \\
\end{cases}
\]</span></p>
<p>Under the given conditions, to maximize the distance <span
class="math inline">\(\frac{2}{||w||}\)</span> between two different
support vectors to the hyperplane, which can be rewritten as an
optimization problem</p>
<p><span class="math display">\[
min_{w,b} \frac 12 {||w||}^2 \\
s.t. y_i(w^Tx_i+b) \geq 1,i=1,2,...,m \\
\]</span></p>
<p>Derivation can be found in the other two blog posts: Machine Learning
Notes and Statistical Learning Method Notes Handwritten Version</p></li>
<li><p>For this optimization problem, its Lagrange equation is</p>
<p><span class="math display">\[
L(w,b,\alpha )=\frac 12 {||w||}^2+\sum _{i=1}^{m} \alpha _i
(1-y_i(w^Tx_i+b))
\]</span></p>
<p>The term <span class="math inline">\(\alpha\)</span> is the Lagrange
multiplier, taking the partial derivatives of the equation with respect
to w and b, obtaining the dual problem</p>
<p><span class="math display">\[
max _{\alpha } \sum _{i=1}^m \alpha _i -\frac 12 \sum _{i=1}^m \sum
_{j=1}^m \alpha _i \alpha _j y_i y_j x_i^T x_j \\
s.t. \sum _{i=1}^m \alpha _i y_i=0, \\
\alpha _i \geq 0,i=1,2,...,m \\
\]</span></p>
<p>The above equation satisfies the KKT conditions, and is solved by the
SMO algorithm</p></li>
</ul>
</div>
<div id="zh-content" class="lang-content" style="display: none;"><h1 id="拉格朗日乘子法">拉格朗日乘子法</h1>
<ul>
<li><p>拉格朗日乘子法是一种求约束条件下极值的方法，描述为</p>
<p><span class="math display">\[
在约束条件g(x,y)=c下 \\
求函数f(x,y)的极值 \\
\]</span></p>
<p>其主要思想是将约束条件和原函数合成一个函数，转换为无约束条件，进而求偏导得到极值。</p></li>
<li><p>由图可以看出，f函数值相等的点可以构成类似等高线的蓝色环，约束条件是绿色的路径。问题可以转换为，我们沿着绿色路径走，走到哪一点时这个点所在的蓝色环最靠中心或者最靠外沿(极大极小值)。</p></li>
<li><p>显然，在绿色路径与蓝色环相切的点取得极值，此时它们的梯度(箭头)平行，描述为</p>
<p><span class="math display">\[
\nabla f (x, y) = \nabla (\lambda \left(g \left(x, y \right) - c
\right))
\]</span></p>
<p><span
class="math inline">\(\lambda\)</span>是拉格朗日乘数，在这个式子中代表两个平行梯度的大小倍数，正负代表两个梯度方向相反。拉格朗日乘数不为0。
拉格朗日方程即$ F(x,y)=$</p></li>
<li><p>求解上面的式子，就得到一组<span
class="math inline">\((x,y,\lambda)\)</span>，即极值点和达到极值时的拉格朗日乘数。此时拉格朗日方程<span
class="math inline">\(F(x,y)=f(x,y)\)</span>，因为取得极值时约束条件部分一定为0(我们是沿着约束条件走找相切点，相切点在约束路径上)。</p></li>
<li><p>拉格朗日系数的含义是最大增长值，<span
class="math inline">\(-\frac{\partial \Lambda}{\partial {c_k}} =
\lambda_k\)</span></p></li>
</ul>
<h1 id="卡罗需-库恩-塔克条件">卡罗需-库恩-塔克条件</h1>
<ul>
<li><p>如果约束条件不仅仅是等式，还包括不等约束条件，这就需将拉格朗日乘子法推广到KKT条件</p></li>
<li><p>包含不等约束的极值问题描述为</p>
<p><span class="math display">\[
在约束条件: \\
h_j(X)=0 j=1,2,...,p \\
g_k(X)\leq 0 k=1,2,...q \\
求函数f(X)的极值 \\
\]</span></p></li>
<li><p>拉格朗日函数为</p>
<p><span class="math display">\[
L(X,\lambda ,\mu)=f(X)+\sum _{j=1}^p \lambda _j h_j(X) + \sum _{k=1}^q
\mu g_k(X)
\]</span></p></li>
<li><p>KKT条件为:</p>
<p><span class="math display">\[
\frac{dL}{dX}=0 \\
\lambda _j \neq 0 \\
\mu _k \geq 0 \\
\mu _k g_k(X)=0 \\
h_j(X)=0 \\
g_k(X) \leq 0\\
\]</span></p></li>
</ul>
<h1 id="pca">PCA</h1>
<ul>
<li><p>PCA即Principal Component
Analysis，主成分分析，将数据原本的维度进行优化，形成一组新的维度，它们是原有维度的线性组合且互不相关，按重要性大小排序，一个维度可以理解为数据矩阵中一列，一行代表一个样本</p></li>
<li><p>记<span
class="math inline">\(x_1,...,x_p\)</span>为原始p个维度，新维度是<span
class="math inline">\(\xi _1,....,\xi _p\)</span></p></li>
<li><p>新维度是原始维度的线性组合，表示为</p>
<p><span class="math display">\[
\xi _i = \sum _{j=1}^{p}  \alpha _{ij} x_j = \alpha _i^T x
\]</span></p></li>
<li><p>为了各个新维度统一尺度，另每个新维度的线性组合系数的向量长度都为1，即</p>
<p><span class="math display">\[
\alpha _i^T \alpha _i=1
\]</span></p></li>
<li><p>令A为特征变换矩阵，由各个新维度的线性组合系数向量构成，则需要求解一个最优的正交变换A，使得新维度的方差达到极值。其中正交变换即保证各个新维度不相关，方差越大则样本在新维度上具有区分度，方便我们进行数据的分类</p></li>
<li><p>此时问题就转化为具有约束条件的极值问题，约束条件为<span
class="math inline">\(\alpha _i^T \alpha _i=1\)</span>，求<span
class="math inline">\(var(\xi
_i)\)</span>的极值，可以用拉格朗日乘子法求解</p></li>
<li><p>当i=1时，我们求出来第一个也是重要性最大(方差最大)的新维度，再令i=2,并加入约束条件<span
class="math inline">\(E[\xi _2 \xi _1\-E[\xi _1][\xi
_2]]=0\)</span>即两个新维度不相关，求出第二个新维度</p></li>
<li><p>依次求出p个新维度</p></li>
<li><p>PCA能够优化原始数据，找出具有区分度的维度，更重要的是如果原始数据的维度存在相关性，PCA能消除这些相关性，即便原始数据相关性很低，如果我们只取前k(k&lt;q)个新维度，就可以在损失较小精确度的情况下进行降维，大大缩短数据的训练时间</p></li>
<li><p>如果我们取了前k个新维度，再对他们进行PCA的逆运算，就可以实现数据的降噪，因为重要性很低的新维度一般反应了数据中的随机噪声，抛弃它们并恢复原始数据时就实现了噪音的去除</p></li>
<li><p>PCA是非监督的，没有考虑样本本身的类别或者标签，在监督学习中不一定是最优解，可以利用K-L变换实现针对分类的目标进行特征提取</p></li>
</ul>
<h1 id="pca-using-covariance-matrix">PCA using Covariance Matrix</h1>
<ul>
<li>上述求解PCA的方法太过于麻烦，在实际中可以通过协方差矩阵来求解（因为有高效的矩阵特征分解算法）</li>
<li>PCA的优化目标是，重新选取一组基（特征），使得数据在这组基表示下，不同特征之间的协方差为0，同一特征内的数据方差最大化</li>
<li>可以将问题转述为，对数据张量X，按特征列（共m个特征）零均值化（化简协方差的计算），计算协方差矩阵<span
class="math inline">\(C=\frac 1m X^T
X\)</span>，希望求得一组基P，使得特征变换后的数据<span
class="math inline">\(Y=PX\)</span>的协方差矩阵D是对角阵，非对角元素（协方差）为0.若对角元素（方差）按从大到小排列，这时我们取P矩阵的前k行就可以将特征维度从m降到k。易得<span
class="math inline">\(D=PCP^T\)</span>，且C为实对称阵，那么问题就转变为对实对称C对角化，我们需要的新的一组基就是特征向量组。</li>
<li>算法：
<ul>
<li><p>有m条n维数据，排成n行m列矩阵X</p></li>
<li><p>将X的每一行进行零均值化</p></li>
<li><p>求出协方差矩阵C</p></li>
<li><p>求出协方差矩阵的特征值和特征向量</p></li>
<li><p>将特征向量按特征值大小对应从大到小按行排列，组成新的基矩阵P</p></li>
<li><p>如果需要将为，取P的前k行即可，降维后的数据为<span
class="math inline">\(Y=PX\)</span></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def PCA(X, dims):</span><br><span class="line">m = len(X)</span><br><span class="line">mean = np.mean(X, axis=0)</span><br><span class="line">X = X - mean</span><br><span class="line">C = np.dot(X.T, X) / m</span><br><span class="line">Eigen_Value, Eigen_Vector = np.linalg.eig(C)</span><br><span class="line">index = np.argsort(Eigen_Value)[-1:-dims - 1:-1]</span><br><span class="line">PCA_Vector = Eigen_Vector[index]</span><br><span class="line">X_PCA = np.dot(PCA_Vector, X.T)</span><br><span class="line">return X_PCA.T</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul>
<h1 id="svm">SVM</h1>
<ul>
<li><p>在分类学习中，我们需要找到一个划分超平面，将不同类别的样本分开，而最好的划分超平面显然是离所分各个样本类尽量远，即对训练样本局部扰动容忍性最好的超平面</p></li>
<li><p>划分超平面通过方程<span
class="math inline">\(w^Tx+b=0\)</span>描述，其中w为法向量，决定了超平面方向，b为超平面到远点的位移</p></li>
<li><p>求解一个SVM，即找到满足约束</p>
<p><span class="math display">\[
\begin{cases}
w^Tx_i+b \geq +1, y_i=+1 \\
w^Tx_i+b \leq -1, y_i=-1 \\
\end{cases}
\]</span></p>
<p>的条件下，使得两个异类支持向量到超平面的距离<span
class="math inline">\(\frac{2}{||w||}\)</span>最大
这可以重写为最优化问题</p>
<p><span class="math display">\[
min_{w,b} \frac 12 {||w||}^2 \\
s.t. y_i(w^Tx_i+b) \geq 1,i=1,2,...,m \\
\]</span></p>
<p>推导见另两篇博文：机器学习笔记和统计学习方法笔记手写版</p></li>
<li><p>对于这个最优化问题，它的拉格朗日方程是</p>
<p><span class="math display">\[
L(w,b,\alpha )=\frac 12 {||w||}^2+\sum _{i=1}^{m} \alpha _i
(1-y_i(w^Tx_i+b))
\]</span></p>
<p>其中<span
class="math inline">\(\alpha\)</span>是拉格朗日乘子，令方程分别对w,b求偏导，得到对偶问题</p>
<p><span class="math display">\[
max _{\alpha } \sum _{i=1}^m \alpha _i -\frac 12 \sum _{i=1}^m \sum
_{j=1}^m \alpha _i \alpha _j y_i y_j x_i^T x_j \\
s.t. \sum _{i=1}^m \alpha _i y_i=0, \\
\alpha _i \geq 0,i=1,2,...,m \\
\]</span></p>
<p>上式满足KKT条件，通过SMO算法求解</p></li>
</ul>
</div>
<script src="https://giscus.app/client.js"
        data-repo="thinkwee/thinkwee.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnk3OTYxNjMwOA=="
        data-category="Announcements"
        data-category-id="DIC_kwDOBL7ZNM4CkozI"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
              <a href="/tags/code/" rel="tag"># code</a>
          </div>

        
  <div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style">
    <a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a>
      <a class="a2a_button_facebook"></a>
      <a class="a2a_button_twitter"></a>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2017/03/09/dachuang/" rel="prev" title="Notes for my Android app - Melodia">
                  <i class="fa fa-angle-left"></i> Notes for my Android app - Melodia
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2017/03/27/oj/" rel="next" title="OJ">
                  OJ <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">ICP/IP地址/域名信息备案管理系统 </a>
      <img src="http://www.beian.gov.cn/img/new/gongan.png" alt=""><a href="https://beian.mps.gov.cn/#/query/webSearch?code=%E4%BA%ACICP%E5%A4%872023015408%E5%8F%B7" rel="noopener" target="_blank">京ICP备2023015408号 </a>
  </div>
  <div class="copyright">
    &copy; 2017 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Thinkwee</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">1.1m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">16:34</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/thinkwee" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.0/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>





  <script src="/js/third-party/addtoany.js"></script>

  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"g58NgfMJBlwTyftr6hizdozq-gzGzoHsz","app_key":"1nA1tNVxeeSlAumHogP0PvSd","server_url":"https://leancloud.cn","security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://thinkwee.top/2017/03/18/Lagrange/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
