<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Serif+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"thinkwee.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"duration":50,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Note for John Mount&#39;s &quot;The Equivalence of Logistic Regression and Maximum Entropy Models&quot; and explains that this proof is a special case of the general derivation proof of the maximum entropy model i">
<meta property="og:type" content="article">
<meta property="og:title" content="Logistic Regression and Maximum Entropy">
<meta property="og:url" content="https://thinkwee.top/2018/10/14/lr-and-me/index.html">
<meta property="og:site_name" content="Thinkwee&#39;s Blog">
<meta property="og:description" content="Note for John Mount&#39;s &quot;The Equivalence of Logistic Regression and Maximum Entropy Models&quot; and explains that this proof is a special case of the general derivation proof of the maximum entropy model i">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.mji.rip/2025/07/16/50e93d01eefd2d64738c372694d4f1fd.png">
<meta property="article:published_time" content="2018-10-14T12:38:59.000Z">
<meta property="article:modified_time" content="2025-07-16T10:38:43.726Z">
<meta property="article:author" content="Thinkwee">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="math">
<meta property="article:tag" content="logistic regression">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.mji.rip/2025/07/16/50e93d01eefd2d64738c372694d4f1fd.png">


<link rel="canonical" href="https://thinkwee.top/2018/10/14/lr-and-me/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://thinkwee.top/2018/10/14/lr-and-me/","path":"2018/10/14/lr-and-me/","title":"Logistic Regression and Maximum Entropy"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Logistic Regression and Maximum Entropy | Thinkwee's Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-96114782-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-96114782-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start --><script>(function() {function calculateHeight(element) {let height = 0;const items = element.children;for (let i = 0; i < items.length; i++) {height += items[i].offsetHeight || 25;const child = items[i].querySelector(".nav-child");if (child && child.style.display !== "none") {height += calculateHeight(child);}}return height;}function generateToc(lang, container) {const content = document.getElementById(lang + "-content");if (!content) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));if (headers.length === 0) return;const ol = document.createElement("ol");ol.className = "nav";let currentLevel = 1;let currentOl = ol;let stack = [ol];let counters = [0, 0, 0, 0, 0, 0];headers.forEach((header, index) => {const level = parseInt(header.tagName[1]);counters[level - 1]++;for (let i = level; i < 6; i++) counters[i] = 0;const li = document.createElement("li");li.className = "nav-item nav-level-" + level;if (level === 1 && index === 0) {li.classList.add("active", "active-current");}const link = document.createElement("a");link.className = "nav-link";if (level === 1 && index === 0) link.classList.add("active");link.href = "#" + header.id;const numSpan = document.createElement("span");numSpan.className = "nav-number";numSpan.textContent = counters.slice(0, level).filter(n => n > 0).join(".");const textSpan = document.createElement("span");textSpan.className = "nav-text";textSpan.textContent = header.textContent;link.appendChild(numSpan);link.appendChild(document.createTextNode(" "));link.appendChild(textSpan);li.appendChild(link);if (level > currentLevel) {const newOl = document.createElement("ol");newOl.className = "nav-child";if (currentLevel === 1) {newOl.style.display = "block";stack[currentLevel - 1].lastElementChild.classList.add("active");}stack[currentLevel - 1].lastElementChild.appendChild(newOl);stack[level - 1] = newOl;currentOl = newOl;} else if (level < currentLevel) {currentOl = stack[level - 1];}currentOl.appendChild(li);currentLevel = level;});container.appendChild(ol);setTimeout(() => {const navHeight = calculateHeight(ol);ol.style.setProperty("--height", navHeight + "px");const navChilds = ol.getElementsByClassName("nav-child");Array.from(navChilds).forEach(child => {if (child.style.display === "block") {const childHeight = calculateHeight(child);child.style.setProperty("--height", childHeight + "px");}});}, 0);return ol;}function updateActiveHeading() {const activeLang = document.getElementById("en-content").style.display === "block" ? "en" : "zh";const content = document.getElementById(activeLang + "-content");const toc = document.getElementById(activeLang + "-toc");if (!content || !toc) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));const scrollPos = window.scrollY + window.innerHeight / 3;let activeHeader = null;for (let i = headers.length - 1; i >= 0; i--) {const header = headers[i];const headerTop = header.getBoundingClientRect().top + window.scrollY;if (headerTop <= scrollPos) {activeHeader = header;break;}}const links = toc.getElementsByClassName("nav-link");Array.from(links).forEach(link => {link.classList.remove("active");const parentLi = link.parentElement;if (parentLi) {parentLi.classList.remove("active", "active-current");}});if (activeHeader) {const activeLink = toc.querySelector(`a[href="#${activeHeader.id}"]`);if (activeLink) {activeLink.classList.add("active");let parent = activeLink.parentElement;while (parent && parent.classList) {if (parent.classList.contains("nav-item")) {parent.classList.add("active");if (parent.classList.contains("nav-level-1")) {parent.classList.add("active-current");}}parent = parent.parentElement;}}}}function initTippy() {document.querySelectorAll(".refplus-num").forEach((ref) => {if (ref._tippy) {ref._tippy.destroy();}let refid = ref.firstChild.href.replace(location.origin+location.pathname,"");let refel = document.querySelector(refid);if (!refel) return;let refnum = refel.dataset.num;let ref_content = refel.innerText.replace(`[${refnum}]`,"");tippy(ref, {content: ref_content,});});}function initToc() {const originalToc = document.querySelector(".post-toc-wrap");if (!originalToc || !document.getElementById("langToggle")) return;const tocContainer = document.createElement("div");tocContainer.className = "post-toc-wrap sidebar-panel sidebar-panel-active";const enToc = document.createElement("div");enToc.id = "en-toc";enToc.className = "post-toc motion-element";enToc.style.display = "block";const zhToc = document.createElement("div");zhToc.id = "zh-toc";zhToc.className = "post-toc motion-element";zhToc.style.display = "none";generateToc("en", enToc);generateToc("zh", zhToc);tocContainer.appendChild(enToc);tocContainer.appendChild(zhToc);originalToc.parentNode.replaceChild(tocContainer, originalToc);window.addEventListener("scroll", updateActiveHeading);setTimeout(updateActiveHeading, 0);}window.toggleLanguage = function() {const enContent = document.getElementById("en-content");const zhContent = document.getElementById("zh-content");const enToc = document.getElementById("en-toc");const zhToc = document.getElementById("zh-toc");const button = document.getElementById("langToggle");if (!enContent || !zhContent || !enToc || !zhToc || !button) return;const isEnglish = enContent.style.display === "block";enContent.style.display = isEnglish ? "none" : "block";zhContent.style.display = isEnglish ? "block" : "none";enToc.style.display = isEnglish ? "none" : "block";zhToc.style.display = isEnglish ? "block" : "none";button.querySelector(".button-text").textContent = isEnglish ? "Switch to English" : "切换中文";setTimeout(updateActiveHeading, 0);setTimeout(initTippy, 100);};document.addEventListener("DOMContentLoaded", function() {initToc();setTimeout(initTippy, 3000);});})();</script><style>.post-toc { transition: all 0.2s ease-in-out; }.post-toc .nav { padding-left: 0; }.post-toc .nav-child { padding-left: 1em; }.post-toc .nav-item { line-height: 1.8; }.post-toc .nav-link { color: #555; }.post-toc .nav-link:hover { color: #222; }.post-toc .nav-link.active { color: #fc6423; }.post-toc .active > .nav-link { color: #fc6423; }.post-toc .active-current > .nav-link { color: #fc6423; }</style><!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Thinkwee's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Too Stupid to Give Up Learning</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">51</span></a></li><li class="menu-item menu-item-multi-agent-ebook"><a href="/multiagent_ebook/" rel="section"><i class="fa fa-book fa-fw"></i>Multi-Agent EBook</a></li><li class="menu-item menu-item-iagents"><a href="/iagents/" rel="section"><i class="fa fa-robot fa-fw"></i>iAgents</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#define-symbols"><span class="nav-number">1.</span> <span class="nav-text">Define symbols</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#logistic-regression"><span class="nav-number">2.</span> <span class="nav-text">Logistic regression</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#softmax-regression"><span class="nav-number">3.</span> <span class="nav-text">Softmax regression</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#solving-softmax"><span class="nav-number">4.</span> <span class="nav-text">Solving softmax</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#balanced-equation"><span class="nav-number">5.</span> <span class="nav-text">Balanced Equation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#from-maximum-entropy-to-softmax"><span class="nav-number">6.</span> <span class="nav-text">From Maximum Entropy to
Softmax</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#solving-parameters"><span class="nav-number">7.</span> <span class="nav-text">Solving Parameters</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#connection-with-the-maximum-entropy-model-defined-by-characteristic-functions"><span class="nav-number">8.</span> <span class="nav-text">Connection
with the Maximum Entropy Model Defined by Characteristic Functions</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%98%8E%E7%A1%AE%E7%AC%A6%E5%8F%B7"><span class="nav-number">9.</span> <span class="nav-text">明确符号</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#logistic%E5%9B%9E%E5%BD%92"><span class="nav-number">10.</span> <span class="nav-text">Logistic回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#softmax%E5%9B%9E%E5%BD%92"><span class="nav-number">11.</span> <span class="nav-text">Softmax回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B1%82%E8%A7%A3softmax"><span class="nav-number">12.</span> <span class="nav-text">求解softmax</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%B3%E8%A1%A1%E7%AD%89%E5%BC%8F"><span class="nav-number">13.</span> <span class="nav-text">平衡等式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%94%B1%E6%9C%80%E5%A4%A7%E7%86%B5%E6%8E%A8%E5%87%BAsoftmax"><span class="nav-number">14.</span> <span class="nav-text">由最大熵推出softmax</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B1%82%E8%A7%A3%E5%8F%82%E6%95%B0"><span class="nav-number">15.</span> <span class="nav-text">求解参数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%8E%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89%E7%9A%84%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%81%94%E7%B3%BB"><span class="nav-number">16.</span> <span class="nav-text">与特征函数定义的最大熵模型的联系</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Thinkwee</p>
  <div class="site-description" itemprop="description">Failed Better</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">51</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">61</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/thinkwee" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;thinkwee" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:thinkwee2767@gmail.com" title="E-Mail → mailto:thinkwee2767@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/thinkwee2767" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;thinkwee2767" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://scholar.google.com/citations?hl=en&user=QvW2leIAAAAJ" title="GScholar → https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl&#x3D;en&amp;user&#x3D;QvW2leIAAAAJ" rel="noopener me" target="_blank"><i class="fa fa-graduation-cap fa-fw"></i>GScholar</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://thinkwee.top/2018/10/14/lr-and-me/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Thinkwee">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Thinkwee's Blog">
      <meta itemprop="description" content="Failed Better">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Logistic Regression and Maximum Entropy | Thinkwee's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Logistic Regression and Maximum Entropy
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2018-10-14 20:38:59" itemprop="dateCreated datePublished" datetime="2018-10-14T20:38:59+08:00">2018-10-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-07-16 18:38:43" itemprop="dateModified" datetime="2025-07-16T18:38:43+08:00">2025-07-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
    </span>

  
    <span id="/2018/10/14/lr-and-me/" class="post-meta-item leancloud_visitors" data-flag-title="Logistic Regression and Maximum Entropy" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>11 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><img data-src="https://i.mji.rip/2025/07/16/50e93d01eefd2d64738c372694d4f1fd.png" width="500"/></p>
<p>Note for John Mount's "The Equivalence of Logistic Regression and
Maximum Entropy Models" and explains that this proof is a special case
of the general derivation proof of the maximum entropy model introduced
in statistical learning methods</p>
<p>Conclusion</p>
<ul>
<li>Maximum entropy model is softmax classification</li>
<li>Under the balanced conditions of the general linear model, the model
mapping function that satisfies the maximum entropy condition is the
softmax function</li>
<li>In the book on Statistical Machine Learning methods, a maximum
entropy model defined under the feature function is presented, which,
along with softmax regression, belongs to the class of log-linear
models</li>
<li>When the feature function extends from a binary function to the
feature value itself, the maximum entropy model becomes a softmax
regression model</li>
<li>The maximum entropy maximizes conditional entropy, not the entropy
of conditional probabilities, nor the entropy of joint
probabilities.</li>
</ul>
<span id="more"></span>
<style>.lang-content {width: 100%;overflow: hidden;}.lang-content:not(:first-child) {display: none;}</style><div style="text-align: right; margin: 0 0 20px auto; max-width: 200px;"><button id="langToggle" onclick="toggleLanguage()" class="lang-switch-btn" style="width: 100%;padding: 10px 20px;border-radius: 8px;border: 2px solid #2c3e50;background-color: #fff;cursor: pointer;color: #2c3e50;font-size: 15px;transition: all 0.3s ease;display: flex;align-items: center;justify-content: center;gap: 8px;box-shadow: 0 2px 4px rgba(0,0,0,0.1);"><span class="button-text">切换中文</span></button></div>
<div id="en-content" class="lang-content" style="display: block;"><h1 id="define-symbols">Define symbols</h1>
<ul>
<li>n-dimensional features, m samples, <span
class="math inline">\(x(i)_j\)</span> denotes the j-th feature of the
i-th sample, discuss the multi-class scenario, the output classification
<span class="math inline">\(y(i)\)</span> has k classes, the mapping
probability function <span class="math inline">\(\pi\)</span> maps from
<span class="math inline">\(R^n\)</span> to <span
class="math inline">\(R^k\)</span> , we hope <span
class="math inline">\(\pi(x(i))_{y(i)}\)</span> to be as large as
possible.</li>
<li>Indicator function <span class="math inline">\(A(u,v)\)</span> ,
equals 1 when <span class="math inline">\(u==v\)</span> and 0
otherwise</li>
</ul>
<h1 id="logistic-regression">Logistic regression</h1>
<p><span class="math display">\[
\pi(x)_1 = \frac{e^{\lambda x}}{1+e^{\lambda x}} \\
\pi(x)_2 = 1 - \pi(x)_1\\
\]</span></p>
<ul>
<li>The parameter to be learned <span
class="math inline">\(\lambda\)</span> is <span
class="math inline">\(R^n\)</span></li>
</ul>
<h1 id="softmax-regression">Softmax regression</h1>
<p><span class="math display">\[
\pi(x)_v = \frac{e^{\lambda _v x}} {\sum _{u=1}^k e^{\lambda _u x}}
\]</span></p>
<ul>
<li>For <span class="math inline">\(R^{k * n}\)</span></li>
</ul>
<h1 id="solving-softmax">Solving softmax</h1>
<ul>
<li><p>When using softmax or logistic as nonlinear functions, they
possess a good property of differentiation, that is, the derivative
function can be expressed in terms of the original function</p></li>
<li><p>We can now define the objective function, which is to maximize
the correct category probability output by the <span
class="math inline">\(\pi\)</span> function (maximum likelihood), and
define the optimization obtained by <span
class="math inline">\(\lambda\)</span> :</p>
<p><span class="math display">\[
\lambda = argmax \sum _{i=1}^m log (\pi (x(i))_{y(i)}) \\
= argmax f(\lambda) \\
\]</span></p></li>
</ul>
<h1 id="balanced-equation">Balanced Equation</h1>
<ul>
<li><p>Derive the objective function above and set the derivative to
0:</p>
<p><span class="math display">\[
\frac {\partial f(\lambda)}{\partial \lambda _{u,j}} = \sum
_{i=1，y(i)=u}^m x(i)_j - \sum _{i=1}^m x(i)_j \pi (x(i))_u =0 \\
\]</span></p></li>
<li><p>Thus, we obtain an important balance equation:</p>
<p><span class="math display">\[
\ \  for \ all \ u,j \\
\sum _{i=1，y(i)=u}^m x(i)_j = \sum _{i=1}^m x(i)_j \pi (x(i))_u \\
\]</span></p></li>
<li><p>Analyze this equation:</p>
<ul>
<li><p>Plain Language: We hope to obtain a mapping function <span
class="math inline">\(\pi\)</span> , such that for a certain dimension
(j) feature, the sum of the weighted feature values of all samples
mapped to the u class by the mapping function is equal to the sum of the
feature values of all samples within the u class. It is obvious that the
best case is that the elements within both summation expressions are
completely identical, only the samples of the u class are summed, and
the probability that the mapping function maps the u class samples to
the u class is 1, while the probability that samples of other classes
are mapped to the u class is 0.</p></li>
<li><p>However, this equation is very lenient, requiring only that the
two sums be equal, without demanding that each element be the same, and
the expression of the mapping function is not explicitly written out.
Any nonlinear mapping that satisfies this equation could be called a
mapping function.</p></li>
<li><p>In formulaic terms, it is expressed as</p>
<p><span class="math display">\[
\sum _{i=1}^m A(u,y(i)) x(i)_j = \sum _{i=1}^m x(i)_j \pi (x(i))_u \\
\pi (x(i))_u \approx A(u,y(i)) \\
\]</span></p></li>
</ul></li>
</ul>
<h1 id="from-maximum-entropy-to-softmax">From Maximum Entropy to
Softmax</h1>
<ul>
<li><p>What was mentioned above is that the balanced equation does not
require the format of the mapping function, then why did we choose
softmax? In other words, under what conditions can the constraint of the
balanced equation lead to the conclusion that the nonlinear mapping is
softmax?</p></li>
<li><p>The answer is maximum entropy. Now let's review the conditions
that need to be met in <span class="math inline">\(\pi\)</span> .</p>
<ul>
<li><p>Balance equation (i.e., this <span
class="math inline">\(\pi\)</span> can fit the data):</p>
<p><span class="math display">\[
\ \  for \ all \ u,j \\
\sum _{i=1，y(i)=u}^m x(i)_j = \sum _{i=1}^m x(i)_j \pi (x(i))_u \\
\]</span></p></li>
<li><p>The output of <span class="math inline">\(\pi\)</span> should be
a probability:</p>
<p><span class="math display">\[
\pi (x)_v \geq 0 \\
\sum _{v=1}^k \pi (x)_v = 1 \\
\]</span></p></li>
</ul></li>
<li><p>According to the maximum entropy principle, we hope that <span
class="math inline">\(\pi\)</span> can have the maximum entropy while
satisfying the aforementioned constraints:</p>
<p><span class="math display">\[
\pi = argmax \ Ent(\pi) \\
Ent(\pi) = - \sum_{v=1}^k \sum _{i=1}^m \pi (x(i))_v log (\pi (x(i))_v)
\\
\]</span></p></li>
<li><p>The maximum entropy can be understood from two perspectives:</p>
<ul>
<li>Maximum entropy, also known as maximum perplexity, refers to the low
risk of overfitting in the model, with low model complexity. According
to Ockham's Razor principle, among multiple models with the same effect,
the one with lower complexity has better generalization ability. Under
the satisfaction of constraint conditions, of course, we would hope for
a model with lower complexity, which is equivalent to
regularization.</li>
<li>The constraints are the parts of our model that are known to need to
be satisfied and need to be fitted; the remaining parts are the unknown
parts, with no rules or data to guide us in assigning probabilities.
What should we do in this unknown situation? In the case of the unknown,
probabilities should be uniformly distributed among all possibilities,
which corresponds to the maximum entropy situation.</li>
</ul></li>
<li><p>The problem has now been formulated as a constrained optimization
problem, which can be solved using the Lagrange multiplier method. There
is a trick; the original text states that it would be somewhat complex
to directly consider the probabilistic inequality conditions, and the
KKT conditions would need to be used, which we will not consider here.
If the <span class="math inline">\(\pi\)</span> obtained satisfies the
inequality conditions, we can skip it (which is indeed the
case).</p></li>
</ul>
<p><span class="math display">\[
L = \sum _{j=1}^n \sum _{v=1}^k \lambda _{v,j} (\sum _{i=1}^m \pi
(x(i))_v x(i)_j - A(v,y(i)) x(i)_j) \\
+ \sum _{v=1}^k \sum _{i=1}^m \beta _i (\pi (x(i))_v -1) \\
- \sum _{v=1}^k \sum _{i=1}^m \pi(x(i))_v log(\pi (x(i))_v) \\
\]</span></p>
<ul>
<li><p>Here is another trick, where we should differentiate all
parameters. Here, we first differentiate <span class="math inline">\(\pi
(x(i))_u\)</span> and set it to 0 to obtain:</p>
<p><span class="math display">\[
\pi (x(i))_u = e^{\lambda _u x(i) + \beta _i -1}
\]</span></p></li>
<li><p>Considering the equality constraint condition (the sum of
probabilities equals 1), it is not necessary to differentiate with
respect to <span class="math inline">\(\beta\)</span></p>
<p><span class="math display">\[
\sum _{v=1}^k e^{\lambda _v x(i) + \beta _i -1} = 1 \\
e^{\beta} = \frac {1}{\sum _{v=1}^k e^{\lambda _v x(i) - 1}} \\
\]</span></p></li>
<li><p>Re-substitution yields:</p>
<p><span class="math display">\[
\pi (x)_u = \frac {e^{\lambda _u}x}{\sum _{v=1}^k e^{\lambda _v}x}
\]</span></p></li>
</ul>
<h1 id="solving-parameters">Solving Parameters</h1>
<ul>
<li>From the time of introducing the balanced equation, it can be seen
that we need to solve <span class="math inline">\(n \* k\)</span>
equations to obtain <span class="math inline">\(n \* k\)</span>
parameters <span class="math inline">\(\lambda\)</span> , or take
partial derivatives of <span class="math inline">\(n \* k\)</span> <span
class="math inline">\(\lambda\)</span> in the Lagrange equation of
maximum entropy, because <span class="math inline">\(\pi\)</span> is a
non-linear function of <span class="math inline">\(\lambda\)</span> .
Both of these methods are relatively difficult, but we can calculate the
Jacobian equations (or the Hessian matrix of the objective function) of
these equations by differentiation, and then we can solve <span
class="math inline">\(\lambda\)</span> using some Newton method, Fisher
Scoring, or iterative method</li>
</ul>
<h1
id="connection-with-the-maximum-entropy-model-defined-by-characteristic-functions">Connection
with the Maximum Entropy Model Defined by Characteristic Functions</h1>
<ul>
<li><p>In this paper, the constraint is (omitted the constraint <span
class="math inline">\(\pi\)</span> must be a probability):</p>
<p><span class="math display">\[
\sum _{i=1，y(i)=u}^m x(i)_j = \sum _{i=1}^m x(i)_j \pi (x(i))_u \\
\]</span></p></li>
<li><p>The maximum entropy is:</p>
<p><span class="math display">\[
Ent(\pi) = - \sum_{v=1}^k \sum _{i=1}^m \pi (x(i))_v log (\pi (x(i))_v)
\\
\]</span></p></li>
<li><p>The results obtained are:</p>
<p><span class="math display">\[
\pi (x)_u = \frac {e^{\lambda _u}x}{\sum _{v=1}^k e^{\lambda _v}x}
\]</span></p></li>
<li><p>In statistical learning methods, the constraints are (with the
probability constraints similarly omitted), where <span
class="math inline">\(P^{*}\)</span> represents the empirical
distribution:</p>
<p><span class="math display">\[
\sum _{x,y} P^{*} (x,y)f(x,y) = \sum _{x,y} P^{*} (x)P(y|x)f(x,y)
\]</span></p></li>
<li><p>The maximum entropy is:</p>
<p><span class="math display">\[
Ent(P) = - \sum _{x,y} P^{*}(x) P(y|x) log P(y|x)
\]</span></p></li>
<li><p>The results obtained are:</p>
<p><span class="math display">\[
P(y|x) = \frac{e^{\sum _i w_i f_i(x,y)}}{\sum _y e^{\sum _i w_i
f_i(x,y)}}
\]</span></p></li>
<li><p>It can be seen that there is a distinction in the representation
of the two; the former directly obtains the form of the softmax
function, but does not maximize the conditional entropy, whereas the
latter is the opposite</p></li>
<li><p>In fact, both are unified. Firstly, the parameters of the model
are all Lagrange multipliers, the former being <span
class="math inline">\(\lambda\)</span> , and the latter being <span
class="math inline">\(w\)</span> , with the relationship:</p>
<p><span class="math display">\[
\lambda = \{w_0,...,w_i,...\}
\]</span></p></li>
<li><p>When the characteristic function extends to the eigenvalue, the
model obtained by both is the same (softmax function):</p>
<p><span class="math display">\[
f_i(x_j,y) = x(j)_i
\]</span></p></li>
<li><p>The balance conditions of both are also consistent. Noticing that
<span class="math inline">\(P^{*}\)</span> is an empirical distribution,
which is statistically obtained through classical probability type on
the training set, in general, repeated data is not considered (with a
total sample size of N and a number of categories K), then:</p>
<p><span class="math display">\[
P^{*} (x) = \frac 1N \\
\sum _{x,y} P^{*} (x,y) = 1 \\
P^{*} (x,y) \in \{0,\frac 1N \} \\
\]</span></p></li>
<li><p>After substitution, it will be found that the balance conditions
of the two are consistent, while the calculation in the paper seems to
be entropy, but it is actually conditional entropy; it merely ignores
the constant condition <span class="math inline">\(P^{*} (x) = \frac
1N\)</span> from the argmax expression and writes it in the form of
entropy.</p></li>
</ul>
</div>
<div id="zh-content" class="lang-content" style="display: none;"><h1 id="明确符号">明确符号</h1>
<ul>
<li>n维特征，m个样本，<span
class="math inline">\(x(i)_j\)</span>表示第i个样本第j维特征，讨论多分类情况，输出分类<span
class="math inline">\(y(i)\)</span>有k类，映射概率函数<span
class="math inline">\(\pi\)</span>从<span
class="math inline">\(R^n\)</span>映射到<span
class="math inline">\(R^k\)</span>，我们希望<span
class="math inline">\(\pi(x(i))_{y(i)}\)</span>尽可能大。</li>
<li>指示函数<span class="math inline">\(A(u,v)\)</span>，当<span
class="math inline">\(u==v\)</span>时为1，否则为0</li>
</ul>
<h1 id="logistic回归">Logistic回归</h1>
<p><span class="math display">\[
\pi(x)_1 = \frac{e^{\lambda x}}{1+e^{\lambda x}} \\
\pi(x)_2 = 1 - \pi(x)_1\\
\]</span></p>
<ul>
<li>其中要学习到的参数<span
class="math inline">\(\lambda\)</span>为<span
class="math inline">\(R^n\)</span></li>
</ul>
<h1 id="softmax回归">Softmax回归</h1>
<p><span class="math display">\[
\pi(x)_v = \frac{e^{\lambda _v x}} {\sum _{u=1}^k e^{\lambda _u x}}
\]</span></p>
<ul>
<li><span class="math inline">\(\lambda\)</span>为<span
class="math inline">\(R^{k * n}\)</span></li>
</ul>
<h1 id="求解softmax">求解softmax</h1>
<ul>
<li><p>当使用softmax或者logistic作为非线性函数时，它们存在一个很好的求导的性质，即导函数可以用原函数表示
<span class="math display">\[
\frac {\partial \pi (x)_v}{\partial \lambda _{v,j}} = x_j  \pi (x)_v
(1-\pi (x)_v) \\
\frac {\partial \pi (x)_v}{\partial \lambda _{u,j}} = -x_j \pi (x)_v \pi
(x)_u \ where \  u \neq v \\
\]</span></p></li>
<li><p>现在我们可以定义目标函数，即希望<span
class="math inline">\(\pi\)</span>函数输出的正确类别概率最大（最大似然），并定义最优化得到的<span
class="math inline">\(\lambda\)</span>：</p>
<p><span class="math display">\[
\lambda = argmax \sum _{i=1}^m log (\pi (x(i))_{y(i)}) \\
= argmax f(\lambda) \\
\]</span></p></li>
</ul>
<h1 id="平衡等式">平衡等式</h1>
<ul>
<li><p>对上面的目标函数求导并令导函数为0：</p>
<p><span class="math display">\[
\frac {\partial f(\lambda)}{\partial \lambda _{u,j}} = \sum
_{i=1，y(i)=u}^m x(i)_j - \sum _{i=1}^m x(i)_j \pi (x(i))_u =0 \\
\]</span></p></li>
<li><p>这样我们就得到一个重要的平衡等式(Balance Equation)：</p>
<p><span class="math display">\[
\ \  for \ all \ u,j \\
\sum _{i=1，y(i)=u}^m x(i)_j = \sum _{i=1}^m x(i)_j \pi (x(i))_u \\
\]</span></p></li>
<li><p>分析这个等式：</p>
<ul>
<li><p>大白话：我们希望得到这么一个映射函数<span
class="math inline">\(\pi\)</span>，对某一维(j)特征，用所有样本被映射函数归为第u类的概率加权所有样本的特征值之和，等于第u类内所有样本的特征值之和。显然，最好的情况就是左右两个累加式内的元素完全一样，只有第u类的样本被累加，且第u类样本被映射函数归为第u类的概率为1，其他类样本被归为第u类样本的概率为0.</p></li>
<li><p>但是，这个等式非常的宽松，它只要求两个和式相同，并不要求每一个元素相同，而且这个式子没有显示的写出映射函数的表达式，任何满足该式的非线性映射都有可能称为映射函数。</p></li>
<li><p>用公式表达，就是</p>
<p><span class="math display">\[
\sum _{i=1}^m A(u,y(i)) x(i)_j = \sum _{i=1}^m x(i)_j \pi (x(i))_u \\
\pi (x(i))_u \approx A(u,y(i)) \\
\]</span></p></li>
</ul></li>
</ul>
<h1 id="由最大熵推出softmax">由最大熵推出softmax</h1>
<ul>
<li><p>上面说到了平衡等式并没有要求映射函数的格式，那么为什么我们选择了softmax？换句话，什么条件下能从平衡等式的约束推出非线性映射为softmax？</p></li>
<li><p>答案是最大熵。我们现在回顾一下<span
class="math inline">\(\pi\)</span>需要满足的条件：</p>
<ul>
<li><p>平衡等式（即这个<span
class="math inline">\(\pi\)</span>能拟合数据）：</p>
<p><span class="math display">\[
\ \  for \ all \ u,j \\
\sum _{i=1，y(i)=u}^m x(i)_j = \sum _{i=1}^m x(i)_j \pi (x(i))_u \\
\]</span></p></li>
<li><p><span class="math inline">\(\pi\)</span>的输出得是一个概率：</p>
<p><span class="math display">\[
\pi (x)_v \geq 0 \\
\sum _{v=1}^k \pi (x)_v = 1 \\
\]</span></p></li>
</ul></li>
<li><p>根据最大熵原理，我们希望满足上述约束条件的<span
class="math inline">\(\pi\)</span>能够具有最大的熵:</p>
<p><span class="math display">\[
\pi = argmax \ Ent(\pi) \\
Ent(\pi) = - \sum_{v=1}^k \sum _{i=1}^m \pi (x(i))_v log (\pi (x(i))_v)
\\
\]</span></p></li>
<li><p>最大熵可以从两个角度理解：</p>
<ul>
<li>最大熵也就是最大困惑度，即模型过拟合的风险低，模型复杂程度低，根据奥卡姆剃刀原则，在多个具有相同效果的模型中复杂程度小的模型具有更好的泛化能力，在满足了约束条件的情况下，当然我们希望要一个复杂程度小的模型，相当于正则化。</li>
<li>约束条件是我们的模型已知的需要满足、需要拟合的部分，剩下的部分是未知的部分，没有规则或者数据指导我们分配概率，那该怎么办？在未知的情况下就应该均匀分配概率给所有可能，这正是对应了最大熵的情况。</li>
</ul></li>
<li><p>现在问题已经形式化带约束条件的最优化问题，利用拉格朗日乘子法求解即可。这里有一个trick，原文中说如果直接考虑概率的不等条件就有点复杂，需要使用KTT条件，这里先不考虑，之后如果求出的<span
class="math inline">\(\pi\)</span>满足不等式条件的话就可以跳过了（事实也正是如此）。</p></li>
</ul>
<p><span class="math display">\[
L = \sum _{j=1}^n \sum _{v=1}^k \lambda _{v,j} (\sum _{i=1}^m \pi
(x(i))_v x(i)_j - A(v,y(i)) x(i)_j) \\
+ \sum _{v=1}^k \sum _{i=1}^m \beta _i (\pi (x(i))_v -1) \\
- \sum _{v=1}^k \sum _{i=1}^m \pi(x(i))_v log(\pi (x(i))_v) \\
\]</span></p>
<ul>
<li><p>这里又有一个trick，本来应该对所有参数求导，这里我们先对<span
class="math inline">\(\pi (x(i))_u\)</span>求导令其为0可得：</p>
<p><span class="math display">\[
\pi (x(i))_u = e^{\lambda _u x(i) + \beta _i -1}
\]</span></p></li>
<li><p>再考虑等式约束条件（概率之和为1），这样就不用再对<span
class="math inline">\(\beta\)</span>求导：</p>
<p><span class="math display">\[
\sum _{v=1}^k e^{\lambda _v x(i) + \beta _i -1} = 1 \\
e^{\beta} = \frac {1}{\sum _{v=1}^k e^{\lambda _v x(i) - 1}} \\
\]</span></p></li>
<li><p>回代可得：</p>
<p><span class="math display">\[
\pi (x)_u = \frac {e^{\lambda _u}x}{\sum _{v=1}^k e^{\lambda _v}x}
\]</span></p></li>
</ul>
<h1 id="求解参数">求解参数</h1>
<ul>
<li>从推出平衡等式的时候可以看到，我们需要解<span
class="math inline">\(n \* k\)</span>个方程来得到<span
class="math inline">\(n \* k\)</span>个参数<span
class="math inline">\(\lambda\)</span>，或者在最大熵的拉格朗日方程里对<span
class="math inline">\(n \* k\)</span>个<span
class="math inline">\(\lambda\)</span>求偏导，因为<span
class="math inline">\(\pi\)</span>是<span
class="math inline">\(\lambda\)</span>的非线性函数，这两种求解方法比较困难，但是我们可以求导计算这些等式的雅各比方程（或者说是目标函数的Hessian矩阵），之后我们就可以用某种牛顿法、Fisher
Scoring或者迭代的方法求解<span
class="math inline">\(\lambda\)</span></li>
</ul>
<h1
id="与特征函数定义的最大熵模型的联系">与特征函数定义的最大熵模型的联系</h1>
<ul>
<li><p>在本文中，约束为（省略了<span
class="math inline">\(\pi\)</span>必须为概率的约束）：</p>
<p><span class="math display">\[
\sum _{i=1，y(i)=u}^m x(i)_j = \sum _{i=1}^m x(i)_j \pi (x(i))_u \\
\]</span></p></li>
<li><p>最大化的熵为：</p>
<p><span class="math display">\[
Ent(\pi) = - \sum_{v=1}^k \sum _{i=1}^m \pi (x(i))_v log (\pi (x(i))_v)
\\
\]</span></p></li>
<li><p>得到的结果为：</p>
<p><span class="math display">\[
\pi (x)_u = \frac {e^{\lambda _u}x}{\sum _{v=1}^k e^{\lambda _v}x}
\]</span></p></li>
<li><p>而在统计学习方法中，约束为（同样省略了概率约束），其中<span
class="math inline">\(P^{*}\)</span>代表经验分布：</p>
<p><span class="math display">\[
\sum _{x,y} P^{*} (x,y)f(x,y) = \sum _{x,y} P^{*} (x)P(y|x)f(x,y)
\]</span></p></li>
<li><p>最大化的熵为：</p>
<p><span class="math display">\[
Ent(P) = - \sum _{x,y} P^{*}(x) P(y|x) log P(y|x)
\]</span></p></li>
<li><p>得到的结果为：</p>
<p><span class="math display">\[
P(y|x) = \frac{e^{\sum _i w_i f_i(x,y)}}{\sum _y e^{\sum _i w_i
f_i(x,y)}}
\]</span></p></li>
<li><p>可以看到两者的表示有区别，前者直接得到了softmax函数的形式，但是最大化的不是条件熵，后者则相反</p></li>
<li><p>实际上两者是统一的。首先，模型的参数都是拉格朗日乘子，前者是<span
class="math inline">\(\lambda\)</span>，后者是<span
class="math inline">\(w\)</span>，两者的关系：</p>
<p><span class="math display">\[
\lambda = \{w_0,...,w_i,...\}
\]</span></p></li>
<li><p>当特征函数扩展到特征值时，两者得到的模型就是一样的（softmax函数）：</p>
<p><span class="math display">\[
f_i(x_j,y) = x(j)_i
\]</span></p></li>
<li><p>两者的平衡条件也是一致的，注意到<span
class="math inline">\(P^{*}\)</span>是经验分布，是在训练集上通过古典概型统计出来的，一般情况下不考虑重复数据（样本总数为N，类别数为K），则有：</p>
<p><span class="math display">\[
P^{*} (x) = \frac 1N \\
\sum _{x,y} P^{*} (x,y) = 1 \\
P^{*} (x,y) \in \{0,\frac 1N \} \\
\]</span></p></li>
<li><p>代入之后会发现两者的平衡条件一致，而论文中计算的貌似是熵，实际上是条件熵，只不过把$P^{*}
(x) = 1N $这一常量条件从argmax表达式中忽略了，写成了熵的形式。</p></li>
</ul>
</div>
<script src="https://giscus.app/client.js"
        data-repo="thinkwee/thinkwee.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnk3OTYxNjMwOA=="
        data-category="Announcements"
        data-category-id="DIC_kwDOBL7ZNM4CkozI"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
              <a href="/tags/math/" rel="tag"># math</a>
              <a href="/tags/logistic-regression/" rel="tag"># logistic regression</a>
          </div>

        
  <div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style">
    <a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a>
      <a class="a2a_button_facebook"></a>
      <a class="a2a_button_twitter"></a>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2018/10/13/compute-future/" rel="prev" title="Future of Computing Salon - Reading Comprehension Session">
                  <i class="fa fa-angle-left"></i> Future of Computing Salon - Reading Comprehension Session
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2018/11/16/coling/" rel="next" title="Notes for Computational Linguistics">
                  Notes for Computational Linguistics <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">ICP/IP地址/域名信息备案管理系统 </a>
      <img src="http://www.beian.gov.cn/img/new/gongan.png" alt=""><a href="https://beian.mps.gov.cn/#/query/webSearch?code=%E4%BA%ACICP%E5%A4%872023015408%E5%8F%B7" rel="noopener" target="_blank">京ICP备2023015408号 </a>
  </div>
  <div class="copyright">
    &copy; 2017 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Thinkwee</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">1.1m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">16:35</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/thinkwee" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.0/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>





  <script src="/js/third-party/addtoany.js"></script>

  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"g58NgfMJBlwTyftr6hizdozq-gzGzoHsz","app_key":"1nA1tNVxeeSlAumHogP0PvSd","server_url":"https://leancloud.cn","security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://thinkwee.top/2018/10/14/lr-and-me/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
