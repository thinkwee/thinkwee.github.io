<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Serif+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"thinkwee.top","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"duration":50,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="A brief review of the VC dimension. All discussions are based on the simple case of binary classification.">
<meta property="og:type" content="article">
<meta property="og:title" content="Note for VC Dimension">
<meta property="og:url" content="https://thinkwee.top/2020/05/15/vc-dimension/index.html">
<meta property="og:site_name" content="Thinkwee&#39;s Blog">
<meta property="og:description" content="A brief review of the VC dimension. All discussions are based on the simple case of binary classification.">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-05-15T08:58:58.000Z">
<meta property="article:modified_time" content="2025-01-30T02:10:45.364Z">
<meta property="article:author" content="Thinkwee">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="math">
<meta property="article:tag" content="statistical learning">
<meta property="article:tag" content="vc dimension">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://thinkwee.top/2020/05/15/vc-dimension/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://thinkwee.top/2020/05/15/vc-dimension/","path":"2020/05/15/vc-dimension/","title":"Note for VC Dimension"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Note for VC Dimension | Thinkwee's Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-96114782-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-96114782-1","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start --><script>(function() {function calculateHeight(element) {let height = 0;const items = element.children;for (let i = 0; i < items.length; i++) {height += items[i].offsetHeight || 25;const child = items[i].querySelector(".nav-child");if (child && child.style.display !== "none") {height += calculateHeight(child);}}return height;}function generateToc(lang, container) {const content = document.getElementById(lang + "-content");if (!content) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));if (headers.length === 0) return;const ol = document.createElement("ol");ol.className = "nav";let currentLevel = 1;let currentOl = ol;let stack = [ol];let counters = [0, 0, 0, 0, 0, 0];headers.forEach((header, index) => {const level = parseInt(header.tagName[1]);counters[level - 1]++;for (let i = level; i < 6; i++) counters[i] = 0;const li = document.createElement("li");li.className = "nav-item nav-level-" + level;if (level === 1 && index === 0) {li.classList.add("active", "active-current");}const link = document.createElement("a");link.className = "nav-link";if (level === 1 && index === 0) link.classList.add("active");link.href = "#" + header.id;const numSpan = document.createElement("span");numSpan.className = "nav-number";numSpan.textContent = counters.slice(0, level).filter(n => n > 0).join(".");const textSpan = document.createElement("span");textSpan.className = "nav-text";textSpan.textContent = header.textContent;link.appendChild(numSpan);link.appendChild(document.createTextNode(" "));link.appendChild(textSpan);li.appendChild(link);if (level > currentLevel) {const newOl = document.createElement("ol");newOl.className = "nav-child";if (currentLevel === 1) {newOl.style.display = "block";stack[currentLevel - 1].lastElementChild.classList.add("active");}stack[currentLevel - 1].lastElementChild.appendChild(newOl);stack[level - 1] = newOl;currentOl = newOl;} else if (level < currentLevel) {currentOl = stack[level - 1];}currentOl.appendChild(li);currentLevel = level;});container.appendChild(ol);setTimeout(() => {const navHeight = calculateHeight(ol);ol.style.setProperty("--height", navHeight + "px");const navChilds = ol.getElementsByClassName("nav-child");Array.from(navChilds).forEach(child => {if (child.style.display === "block") {const childHeight = calculateHeight(child);child.style.setProperty("--height", childHeight + "px");}});}, 0);return ol;}function updateActiveHeading() {const activeLang = document.getElementById("en-content").style.display === "block" ? "en" : "zh";const content = document.getElementById(activeLang + "-content");const toc = document.getElementById(activeLang + "-toc");if (!content || !toc) return;const headers = Array.from(content.querySelectorAll("h1, h2, h3, h4, h5, h6"));const scrollPos = window.scrollY + window.innerHeight / 3;let activeHeader = null;for (let i = headers.length - 1; i >= 0; i--) {const header = headers[i];const headerTop = header.getBoundingClientRect().top + window.scrollY;if (headerTop <= scrollPos) {activeHeader = header;break;}}const links = toc.getElementsByClassName("nav-link");Array.from(links).forEach(link => {link.classList.remove("active");const parentLi = link.parentElement;if (parentLi) {parentLi.classList.remove("active", "active-current");}});if (activeHeader) {const activeLink = toc.querySelector(`a[href="#${activeHeader.id}"]`);if (activeLink) {activeLink.classList.add("active");let parent = activeLink.parentElement;while (parent && parent.classList) {if (parent.classList.contains("nav-item")) {parent.classList.add("active");if (parent.classList.contains("nav-level-1")) {parent.classList.add("active-current");}}parent = parent.parentElement;}}}}function initTippy() {document.querySelectorAll(".refplus-num").forEach((ref) => {if (ref._tippy) {ref._tippy.destroy();}let refid = ref.firstChild.href.replace(location.origin+location.pathname,"");let refel = document.querySelector(refid);if (!refel) return;let refnum = refel.dataset.num;let ref_content = refel.innerText.replace(`[${refnum}]`,"");tippy(ref, {content: ref_content,});});}function initToc() {const originalToc = document.querySelector(".post-toc-wrap");if (!originalToc || !document.getElementById("langToggle")) return;const tocContainer = document.createElement("div");tocContainer.className = "post-toc-wrap sidebar-panel sidebar-panel-active";const enToc = document.createElement("div");enToc.id = "en-toc";enToc.className = "post-toc motion-element";enToc.style.display = "block";const zhToc = document.createElement("div");zhToc.id = "zh-toc";zhToc.className = "post-toc motion-element";zhToc.style.display = "none";generateToc("en", enToc);generateToc("zh", zhToc);tocContainer.appendChild(enToc);tocContainer.appendChild(zhToc);originalToc.parentNode.replaceChild(tocContainer, originalToc);window.addEventListener("scroll", updateActiveHeading);setTimeout(updateActiveHeading, 0);}window.toggleLanguage = function() {const enContent = document.getElementById("en-content");const zhContent = document.getElementById("zh-content");const enToc = document.getElementById("en-toc");const zhToc = document.getElementById("zh-toc");const button = document.getElementById("langToggle");if (!enContent || !zhContent || !enToc || !zhToc || !button) return;const isEnglish = enContent.style.display === "block";enContent.style.display = isEnglish ? "none" : "block";zhContent.style.display = isEnglish ? "block" : "none";enToc.style.display = isEnglish ? "none" : "block";zhToc.style.display = isEnglish ? "block" : "none";button.querySelector(".button-text").textContent = isEnglish ? "Switch to English" : "切换中文";setTimeout(updateActiveHeading, 0);setTimeout(initTippy, 100);};document.addEventListener("DOMContentLoaded", function() {initToc();setTimeout(initTippy, 3000);});})();</script><style>.post-toc { transition: all 0.2s ease-in-out; }.post-toc .nav { padding-left: 0; }.post-toc .nav-child { padding-left: 1em; }.post-toc .nav-item { line-height: 1.8; }.post-toc .nav-link { color: #555; }.post-toc .nav-link:hover { color: #222; }.post-toc .nav-link.active { color: #fc6423; }.post-toc .active > .nav-link { color: #fc6423; }.post-toc .active-current > .nav-link { color: #fc6423; }</style><!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Thinkwee's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Too Stupid to Give Up Learning</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">52</span></a></li><li class="menu-item menu-item-multi-agent-ebook"><a href="/multiagent_ebook/" rel="section"><i class="fa fa-book fa-fw"></i>Multi-Agent EBook</a></li><li class="menu-item menu-item-iagents"><a href="/iagents/" rel="section"><i class="fa fa-robot fa-fw"></i>iAgents</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#hoeffdings-inequality"><span class="nav-number">1.</span> <span class="nav-text">Hoeffding&#39;s Inequality</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#effective-hypotheses"><span class="nav-number">2.</span> <span class="nav-text">Effective Hypotheses</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#vc-dimension"><span class="nav-number">3.</span> <span class="nav-text">VC Dimension</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#measuring-generalization-ability"><span class="nav-number">4.</span> <span class="nav-text">Measuring Generalization
Ability</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#references"><span class="nav-number">5.</span> <span class="nav-text">References</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hoeffding%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="nav-number">6.</span> <span class="nav-text">Hoeffding不等式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%89%E6%95%88%E7%9A%84%E5%81%87%E8%AE%BE"><span class="nav-number">7.</span> <span class="nav-text">有效的假设</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#vc%E7%BB%B4"><span class="nav-number">8.</span> <span class="nav-text">VC维</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%A1%A1%E9%87%8F%E9%87%8F%E5%8C%96%E8%83%BD%E5%8A%9B"><span class="nav-number">9.</span> <span class="nav-text">衡量量化能力</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">10.</span> <span class="nav-text">参考</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Thinkwee</p>
  <div class="site-description" itemprop="description">Failed Better</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">59</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/thinkwee" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;thinkwee" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:thinkwee2767@gmail.com" title="E-Mail → mailto:thinkwee2767@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/thinkwee2767" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;thinkwee2767" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://scholar.google.com/citations?hl=en&user=QvW2leIAAAAJ" title="GScholar → https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl&#x3D;en&amp;user&#x3D;QvW2leIAAAAJ" rel="noopener me" target="_blank"><i class="fa fa-graduation-cap fa-fw"></i>GScholar</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="sidebar-inner sidebar-post-related">
          <div class="animated">
              <div class="links-of-blogroll-title"><i class="fa fa-signs-post fa-fw"></i>
    Related Posts
  </div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2019/07/29/CorEx/" rel="bookmark">
        <time class="popular-posts-time">2019-07-29</time>
        <br>
      Study Notes for Correlation Explaination
      </a>
    </li>
  </ul>

          </div>
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://thinkwee.top/2020/05/15/vc-dimension/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Thinkwee">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Thinkwee's Blog">
      <meta itemprop="description" content="Failed Better">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Note for VC Dimension | Thinkwee's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Note for VC Dimension
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-05-15 16:58:58" itemprop="dateCreated datePublished" datetime="2020-05-15T16:58:58+08:00">2020-05-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-01-30 10:10:45" itemprop="dateModified" datetime="2025-01-30T10:10:45+08:00">2025-01-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
    </span>

  
    <span id="/2020/05/15/vc-dimension/" class="post-meta-item leancloud_visitors" data-flag-title="Note for VC Dimension" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>16k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>15 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>A brief review of the VC dimension. All discussions are based on the
simple case of binary classification.</p>
<span id="more"></span>
<style>.lang-content {width: 100%;overflow: hidden;}.lang-content:not(:first-child) {display: none;}</style><div style="text-align: right; margin: 0 0 20px auto; max-width: 200px;"><button id="langToggle" onclick="toggleLanguage()" class="lang-switch-btn" style="width: 100%;padding: 10px 20px;border-radius: 8px;border: 2px solid #2c3e50;background-color: #fff;cursor: pointer;color: #2c3e50;font-size: 15px;transition: all 0.3s ease;display: flex;align-items: center;justify-content: center;gap: 8px;box-shadow: 0 2px 4px rgba(0,0,0,0.1);"><span class="button-text">切换中文</span></button></div>
<div id="en-content" class="lang-content" style="display: block;"><h1 id="hoeffdings-inequality">Hoeffding's Inequality</h1>
<ul>
<li><p>A major assumption in machine learning is that the model trained
on the training set can generalize to the test set. More specifically,
using algorithm A and training set D, we find a hypothesis g in the
hypothesis space H that approximates the target hypothesis f. Let <span
class="math inline">\(E_{in}(g)\)</span> represent the error (empirical
error) on the training set, and <span
class="math inline">\(E_{out}(g)\)</span> represent the error
(generalization error, expected error) on all possible samples outside
the training set.</p></li>
<li><p>Given <span class="math inline">\(E_{out}(f) = 0\)</span>, we
also hope that the obtained g satisfies <span
class="math inline">\(E_{out}(g) = 0\)</span>, which contains two pieces
of information:</p>
<ul>
<li>We need <span class="math inline">\(E_{in}(g) \approx
E_{out}(g)\)</span></li>
<li>We need <span class="math inline">\(E_{in}(g) \approx
0\)</span></li>
</ul></li>
<li><p>The second point <span class="math inline">\(E_{in}(g) \approx
0\)</span> is what we do when training the model, reducing the error on
the training set, while the first point <span
class="math inline">\(E_{in}(g) \approx E_{out}(g)\)</span>, i.e., how
to ensure the model's generalization ability, is what VC dimension
measures.</p></li>
<li><p>The training set can be seen as a sampling of the sample space,
and we use Hoeffding's inequality to estimate quantities of the entire
sample space from the sampling:</p>
<p><span class="math display">\[
\mathbb{P}[|\nu-\mu|&gt;\epsilon] \leq 2 \exp \left(-2 \epsilon^{2}
N\right)
\]</span></p></li>
<li><p>Where <span class="math inline">\(\nu\)</span> is the calculated
quantity on the training set, <span class="math inline">\(\mu\)</span>
is the corresponding quantity on the entire sample space. Naturally, we
can view error (loss) as a kind of calculation, giving:</p>
<p><span class="math display">\[
\mathbb{P}\left[\left|E_{i n}(h)-E_{o u t}(h)\right|&gt;\epsilon\right]
\leq 2 \exp \left(-2 \epsilon^{2} N\right)
\]</span></p></li>
<li><p>Here h is a certain hypothesis (any one, not the best hypothesis
g we selected through training). The left side is the probability of the
difference between training and true loss exceeding a certain threshold,
which can be used to measure generalization ability. The right side
depends only on the difference threshold and training set size N. This
aligns with our intuition that the larger the training set, the stronger
the generalization ability.</p></li>
<li><p>However, the above situation is for a fixed hypothesis h. We call
the case where the empirical error and generalization error differ
greatly a "bad case". The above inequality shows that for a fixed h, the
probability of a bad case occurring is very small. But our algorithm A
selects hypotheses from the entire hypothesis space H. We are more
concerned with the probability that no h among all h experiences a bad
case, i.e.:</p>
<p><span class="math display">\[
\begin{array}{c}
\mathbb{P}\left[\mathbf{E}\left(h_{1}\right)&gt;\epsilon \cup
\mathbf{E}\left(h_{2}\right)&gt;\epsilon \ldots \cup
\mathbf{E}\left(h_{M}\right)&gt;\epsilon\right] \\
\leq
\mathbb{P}\left[\mathbf{E}\left(h_{1}\right)&gt;\epsilon\right]+\mathbb{P}\left[\mathbf{E}\left(h_{2}\right)&gt;\epsilon\right]
\ldots+\mathbb{P}\left[\mathbf{E}\left(h_{M}\right)&gt;\epsilon\right]
\\
\leq 2 M \exp \left(-2 \epsilon^{2} N\right)
\end{array}
\]</span></p></li>
<li><p>Where <span class="math inline">\(\mathbf{E}\)</span> represents
the difference between empirical error and generalization error. Here we
further bound this upper limit, considering the maximum case, assuming
the events of each h's empirical and generalization errors differing
beyond a certain threshold are independent. The probability of the union
of events is the sum of individual event probabilities. We ultimately
obtain an upper limit of bad cases for all h as <span
class="math inline">\(2 M \exp (-2 \epsilon^{2} N)\)</span></p></li>
<li><p>Now we've encountered a problem. Previously, since only N existed
in the negative exponential term, as long as the training set size was
large enough, this upper limit was finite, giving us confidence in
machine learning's generalization ability. Now, with an M (the capacity
of the hypothesis space) multiplied in front, the upper limit may no
longer be finite. This also aligns with intuition: imagine that the
larger the hypothesis space, the more data is needed to train and select
a good hypothesis. If the data volume is fixed, the larger the
hypothesis space, the harder it is to select a g close to the true
hypothesis f.</p></li>
</ul>
<h1 id="effective-hypotheses">Effective Hypotheses</h1>
<ul>
<li><p>Next, we formally enter the discussion of VC dimension. First, we
discuss the number of effective hypotheses. Considering the above
inequality, we made a large approximation by assuming that the events of
each h's empirical and generalization errors differing beyond a
threshold are independent, and the probability of the union of events is
the sum of individual event probabilities. But this is not actually the
case. For example, for two-dimensionally linearly separable data with
separation intervals, several parallel separation planes (lines) that
correctly classify the training set and are close to each other have
very similar characteristics. For most data points, the results under
these two separation planes are the same, and the probability
distribution of generalization ability differences also has significant
overlap. Treating them as independent is inappropriate.</p></li>
<li><p>Let's look again at M in the inequality, which literally means
the capacity of the hypothesis space, actually a measure of the
hypothesis space's expression capability. Under a certain amount of
training data, the richer the hypothesis space's expression ability, the
harder it is for the learning algorithm to find a good hypothesis. The
capacity of the hypothesis space is the sum of all hypotheses, where one
hypothesis can be seen as a set of parameters under a specific model. Is
there a more effective measure of the hypothesis space's expression
ability?</p></li>
<li><p>What if we look at the model's classification results instead of
the model parameters themselves? For example, previously we considered
hypotheses with the same parameters (same line) as the same hypothesis.
Now, we consider hypotheses with the same classification results
(different lines that classify points the same way) as the same
hypothesis. This seems more reasonable because expression capability
ultimately falls on handling all possible classification results of the
data, and both empirical and generalization errors are measured through
misclassified points.</p></li>
<li><p>Here we introduce several terms:</p>
<ul>
<li>Dichotomy: Denoted as <span class="math inline">\(h\left(X_{1},
X_{2}, \ldots, X_{N}\right)\)</span>. The dichotomy of N points is a
classification result of N points. For binary classification, there can
be at most <span class="math inline">\(2^N\)</span> dichotomies.</li>
<li>Dichotomies of hypothesis space H on N points in training set D,
denoted as <span class="math inline">\(\mathcal{H}\left(X_{1}, X_{2},
\ldots, X_{N}\right)\)</span>. The number of dichotomies depends not
only on the dataset but also on the hypothesis space H, because the
hypothesis space may not achieve all dichotomies. For example, for four
points forming a square with diagonal labels the same, a linear
hypothesis space cannot achieve this dichotomy.</li>
<li>Growth function: The number of dichotomies in the hypothesis space
on the training set depends not only on the training set size but also
on the specific training set. For example, if the extracted training set
does not include (four points forming a square with diagonal labels the
same), the number of dichotomies for lines on this training set might be
the same as the maximum possible dichotomies for this training set.
Therefore, to exclude the influence of specific training sets, we define
the maximum number of dichotomies the hypothesis space H can achieve on
all possible training sets of size N as the growth function: <span
class="math inline">\(m_{\mathcal{H}}(N)=\max _{X_{1}, X 2, \ldots,
X_{N} \in \mathcal{X}}\left|\mathcal{H}\left(X_{1}, X_{2}, \ldots,
X_{N}\right)\right|\)</span></li>
<li>Shatter: When the growth function reaches the theoretically maximum
dichotomy of <span class="math inline">\(2^N\)</span>. The meaning here
is that this hypothesis space is good enough for a dataset of size N
(for any dataset of size N in this task setting), capable of considering
all situations and providing corresponding hypotheses for any
classification result. That is, for a dataset with total capacity N, the
model can achieve a perfect solution.</li>
<li>Break point: Obviously, the smaller N is, the easier it is to
shatter; the larger N is, the harder it is to shatter. Starting from N=1
and gradually increasing until a critical point N=k where the hypothesis
space cannot shatter these k points, we call k the break point of this
hypothesis space. It can be proven that for N&gt;k, shattering is
impossible.</li>
</ul></li>
<li><p>We can see that the growth function is actually a measure of the
hypothesis space's expression capability. VC dimension considers using
this measure to replace the hypothesis space capacity in the Hoeffding
inequality. Of course, it cannot be directly substituted.
Specifically:</p>
<p><span class="math display">\[
\forall g \in \mathcal{H}, \mathbb{P}\left[\left|E_{i n}(g)-E_{o u
t}(g)\right|&gt;\epsilon\right] \leq 4 m_{\mathcal{H}}(2 N) \exp
\left(-\frac{1}{8} \epsilon^{2} N\right)
\]</span></p></li>
<li><p>The right side is the VC bound, which is complex to prove and
omitted. Now let's consider whether the upper bound is finite. We can
see that the important M has been replaced by <span
class="math inline">\(m_H\)</span>, the growth function. If the growth
function is bounded or its growth rate with N is lower than the
reduction rate of the exponential part, we can say that the upper bound
of the difference between empirical and generalization errors is finite.
In fact, if a break point k exists, then:</p>
<p><span class="math display">\[
m_{\mathcal{H}}(N) \leq B(N, k) \leq
\sum_{i=0}^{k-1}\left(\begin{array}{c}
N \\
i
\end{array}\right) \leq N^{k-1}
\]</span></p></li>
<li><p>Where B(N, k) is the upper bound of the growth function when the
break point is k. We can see that the upper bound of the growth function
is polynomial-level (k-1 power), so the growth function is at most
polynomial-level, while the VC bound's <span class="math inline">\(\exp
\left(-2 \epsilon^{2} N\right)\)</span> is exponential-level. Clearly,
the VC bound exists and is finite.</p></li>
<li><p>Finally, for cases where a break point exists, we can say that
generalization ability is guaranteed, and machine learning is
viable.</p></li>
</ul>
<h1 id="vc-dimension">VC Dimension</h1>
<ul>
<li><p>The VC bound ensures the feasibility of learning, while VC
dimension considers the expression capability of the hypothesis space.
We previously discussed the growth function as a measure of the
hypothesis space's expression capability, and the two are closely
related.</p></li>
<li><p>The VC dimension is defined as follows: Given a hypothesis space
H with an existing break point, the VC dimension is the size of the
largest dataset that can be shattered, i.e.:</p>
<p><span class="math display">\[
V C(\mathcal{H})=\max \left\{N: m_{\mathcal{H}}(N)=2^{N}\right\}
\]</span></p></li>
<li><p>Recall the two concepts in the VC dimension definition: growth
function and shattering. The growth function defines the hypothesis
space's ability to solve dichotomies, and shattering represents the
hypothesis space's ability to handle a certain amount of dataset, with a
corresponding hypothesis for each possible dichotomy. The VC dimension
measures the hypothesis space's capability from the perspective of
dataset size. The more complex the hypothesis space and the stronger its
expression capability, the larger the dataset it can shatter, with
sufficient hypotheses to solve every possible dichotomy on a larger
dataset - note that this is not every theoretically possible dichotomy,
because the VC dimension takes the maximum dataset size that can
actually be shattered, meaning the largest existing dataset size that
can be shattered by this hypothesis space.</p></li>
<li><p>So what exactly is the VC dimension? We actually defined it
earlier: it's k-1, meaning datasets with capacity less than the break
point can be shattered, so the maximum dataset size that can be
shattered is the break point - 1.</p></li>
<li><p>Notice that this k-1 is the polynomial degree in the growth
function's upper bound of the VC bound, so the VC bound can also be
written as:</p>
<p><span class="math display">\[
\forall g \in \mathcal{H}, \mathbb{P}\left[\left|E_{i n}(g)-E_{o u
t}(g)\right|&gt;\epsilon\right] \leq 4(2 N)^{V C(\mathcal{H})} \exp
\left(-\frac{1}{8} \epsilon^{2} N\right)
\]</span></p></li>
</ul>
<h1 id="measuring-generalization-ability">Measuring Generalization
Ability</h1>
<ul>
<li><p>From the VC bound inequality, we can see that the difference
between empirical error and generalization error (measuring
generalization ability) is associated with the probability of bad cases
on the right side of the inequality. If we specify the probability of
bad cases occurring as:</p>
<p><span class="math display">\[
4(2 N)^{V C(\mathcal{H})} \exp \left(-\frac{1}{8} \epsilon^{2}
N\right)=\delta
\]</span></p>
<p>We can conversely calculate the difference measuring generalization
ability:</p>
<p><span class="math display">\[
\epsilon=\sqrt{\frac{8}{N} \ln \left(\frac{4(2 N)^{V
C(\mathcal{H})}}{\delta}\right)}
\]</span></p></li>
<li><p>Therefore, in machine learning foundations and techniques,
teachers often write a VC bound to estimate the generalization error
formula:</p>
<p><span class="math display">\[
E_{\text {out }}(\mathbf{w}) \leq E_{\text {in
}}(\mathbf{w})+\Omega(\mathcal{H})
\]</span></p></li>
<li><p>Where <span class="math inline">\(\Omega(\mathcal{H})\)</span> is
<span class="math inline">\(\sqrt{\frac{8}{N} \ln \left(\frac{4(2 N)^{V
C(\mathcal{H})}}{\delta}\right)}\)</span></p></li>
</ul>
<h1 id="references">References</h1>
<ul>
<li>https://zhuanlan.zhihu.com/p/59113933</li>
<li>https://www.coursera.org/learn/ntumlone-mathematicalfoundations</li>
</ul>
</div>
<div id="zh-content" class="lang-content" style="display: none;"><h1 id="hoeffding不等式">Hoeffding不等式</h1>
<ul>
<li><p>机器学习的一个大假设就是，训练集上训练出的模型能够泛化到测试集，详细一点说即我们用算法A和训练集D，在假设空间H里中找到一个假设g，使得该假设g和需要学习的目标假设f近似。令g在训练集上的误差（经验误差）为<span
class="math inline">\(E_{in}(g)\)</span>，在除了训练集外所有可能样本上的误差（泛化误差，期望误差）为<span
class="math inline">\(E_{out}(g)\)</span>。</p></li>
<li><p>已知<span class="math inline">\(E_{out}(f) =
0\)</span>，我们也希望得到的g满足<span class="math inline">\(E_{out}(g)
= 0\)</span>，这里包含了两点信息</p>
<ul>
<li>需要<span class="math inline">\(E_{in}(g) \approx
E_{out}(g)\)</span></li>
<li>需要<span class="math inline">\(E_{in}(g) \approx 0\)</span></li>
</ul></li>
<li><p>第二点<span class="math inline">\(E_{in}(g) \approx
0\)</span>就是我们训练模型所做的事，在训练集上减小误差，而第一点<span
class="math inline">\(E_{in}(g) \approx
E_{out}(g)\)</span>，即如何保证模型的泛化能力，这是VC所衡量的事情。</p></li>
<li><p>训练集可以看成是样本空间的一个采样，从采样上计算一些量来估计整个样本空间的量，我们有Hoeffding不等式</p>
<p><span class="math display">\[
\mathbb{P}[|\nu-\mu|&gt;\epsilon] \leq 2 \exp \left(-2 \epsilon^{2}
N\right)
\]</span></p></li>
<li><p>其中<span
class="math inline">\(\nu\)</span>是训练集上的计算量，<span
class="math inline">\(\mu\)</span>是整个样本空间上对应的量。我们自然可以把误差（损失）看成是一种计算量，得到：</p>
<p><span class="math display">\[
\mathbb{P}\left[\left|E_{i n}(h)-E_{o u t}(h)\right|&gt;\epsilon\right]
\leq 2 \exp \left(-2 \epsilon^{2} N\right)
\]</span></p></li>
<li><p>其中h是某一假设（任意一个，不是我们通过训练挑出的最好假设g），左边即训练和真实损失差距大于某个相差阈值的概率，可以用来衡量泛化能力，而右侧发现只和相差阈值和训练集容量N相关。这符合我们的直觉，即训练集越大，泛化能力越强。</p></li>
<li><p>但问题是以上情况是针对固定的一个假设h，我们称经验误差和泛化误差相差很多的情况为bad
case，那上述不等式说明了对于固定的一个h，bad
case出现的概率很小。但是我们的算法A是在整个假设空间H里挑选假设，我们更关注对于所有h，其中任意一个h都不出现bad
case出现的概率，即</p>
<p><span class="math display">\[
\begin{array}{c}
\mathbb{P}\left[\mathbf{E}\left(h_{1}\right)&gt;\epsilon \cup
\mathbf{E}\left(h_{2}\right)&gt;\epsilon \ldots \cup
\mathbf{E}\left(h_{M}\right)&gt;\epsilon\right] \\
\leq
\mathbb{P}\left[\mathbf{E}\left(h_{1}\right)&gt;\epsilon\right]+\mathbb{P}\left[\mathbf{E}\left(h_{2}\right)&gt;\epsilon\right]
\ldots+\mathbb{P}\left[\mathbf{E}\left(h_{M}\right)&gt;\epsilon\right]
\\
\leq 2 M \exp \left(-2 \epsilon^{2} N\right)
\end{array}
\]</span></p></li>
<li><p>其中<span
class="math inline">\(\mathbf{E}\)</span>即经验误差和泛化误差的差距，这里我们进一步放缩了这个上界，考虑最大的情况，也就是各个h经验误差和泛化误差的差距大于某个阈值的事件相互独立，事件的并的概率是各个事件概率之和，最终得到了针对所有h，bad
case的上限是<span class="math inline">\(2 M \exp (-2 \epsilon^{2}
N)\)</span></p></li>
<li><p>这下就出了问题，之前由于只有N存在于负指数项中，所以只要训练集容量足够大，这个上限是有限的，我们就对机器学习的泛化能力有信心；现在前面乘了一个M，即假设空间的容量，这下上限就不一定是有限（存在）的了。这也符合直觉，想象一下，假设空间越大，就需要越多的数据来训练，使得算法挑选出一个好的假设；假如数据量一定，假设空间越大，就越难挑出一个和真实假设f相近的g</p></li>
</ul>
<h1 id="有效的假设">有效的假设</h1>
<ul>
<li><p>接下来正式进入VC维的探讨。首先我们讨论有效假设数。考虑到上面的不等式，我们其实做了一个很大的放缩，即假定各个h经验误差和泛化误差的差距大于某个阈值的事件相互独立，事件的并的概率是各个事件概率之和。但实际上并不是这样的。例如对于二维线性可分的数据，存在分离间隔，那么分离间隔中的几个能正确分类训练集的几个相互平行且相差不远的分离面（直线），他们其实非常相近，对于绝大多数数据点而言在这两个分离面下的结果相同，同样泛化能力出现差距的概率分布也有很大重叠，将其视为相互独立是不合适的。</p></li>
<li><p>我们再回头看看不等式中的M，其字面意思就是假设空间的容量，实际上是假设空间表达能力的一种度量，在一定量的训练集下，假设空间表达能力越丰富，学习算法就越难找到一个好的假设。假设空间的容量，是所有假设的和，其中一个假设可以看成是确定模型下的一组参数。有没有其他的更为有效的衡量假设空间表达能力的量？</p></li>
<li><p>假如我们不看模型参数本身，而是看模型对数据的分类结果呢？例如，之前是相同的参数（相同的直线）视为相同的假设，现在用相同的分类结果（不同的直线，把点做了相同的分类）的参数视为相同的假设。这样看来似乎更加合理，因为表达能力最终落实在对数据的所有可能分类结果的处理，而无论经验误差还是泛化误差也都是通过误分类点来衡量。</p></li>
<li><p>这里引入了几个术语：</p>
<ul>
<li>对分(dichotomy)：记为<span class="math inline">\(h\left(X_{1},
X_{2}, \ldots,
X_{N}\right)\)</span>。N个点的对分即N个点的一种分类结果，显然对于二分类问题，N个点最多有<span
class="math inline">\(2^N\)</span>个dichotomy。</li>
<li>假设空间H在训练集D里N个点上的对分，记为<span
class="math inline">\(\mathcal{H}\left(X_{1}, X_{2}, \ldots,
X_{N}\right)\)</span>，这里对分的个数除了和数据集相关，还和假设空间H相关，因为假设空间并不一定能取到所有的dichotomy，例如四个点组成正方形，对角线的标签一样，那么一条直线的假设空间就取不到这种对分。</li>
<li>增长函数(growth
function)：假设空间在训练集上的对分个数不仅与训练集大小相关，还与具体的训练集相关，例如抽出来的训练集不包含（四个点组成正方形，对角线的标签一样）这种对分，那么可能直线在该训练集上取到的对分数量就和该训练集最多可能的对分数量一样。因此为了排除具体的训练集影响，我们设在所有大小为N的可能训练集上假设空间H能取到的最大对分数量为增长函数，定为：<span
class="math inline">\(m_{\mathcal{H}}(N)=\max _{X_{1}, X 2, \ldots,
X_{N} \in \mathcal{X}}\left|\mathcal{H}\left(X_{1}, X_{2}, \ldots,
X_{N}\right)\right|\)</span></li>
<li>打散(shatter)：即增长函数取到了理论上最大的对分数<span
class="math inline">\(2^N\)</span>，这里的含义就是这个假设空间对于大小为N的数据集（该任务设定下任意一个大小为N数据集）来说足够好了，能够考虑到所有情况，针对任何一种分类结果给出对应的假设。也即对于该任务，总容量为N的数据集，该模型有能力取到完美解。</li>
<li>break
point：显然N越小，越容易打散；N越大，越不容易打散。那么从N=1开始逐渐增加，直到某个临界点N=k时，假设空间无法打散这k个点了，我们就称k为该假设空间的break
point。可以证明N&gt;k的情况都无法打散</li>
</ul></li>
<li><p>可以看到其实到增长函数这里，这就是一个假设空间表达能力的一种衡量指标了。VC维考虑的就是用这种衡量指标替换Hoeffding不等式中的假设空间容量。当然不能直接替换，具体而言，是</p>
<p><span class="math display">\[
\forall g \in \mathcal{H}, \mathbb{P}\left[\left|E_{i n}(g)-E_{o u
t}(g)\right|&gt;\epsilon\right] \leq 4 m_{\mathcal{H}}(2 N) \exp
\left(-\frac{1}{8} \epsilon^{2} N\right)
\]</span></p></li>
<li><p>上式右边即VC界，证明比较复杂略。那么这样我们再考虑上界是不是有限的。可以看到最重要的M被换成了<span
class="math inline">\(m_H\)</span>，即增长函数，假如增长函数有界或者说随N的增加速率低于指数部分的缩减速率，那么我们就可以说经验误差和泛化误差的差值上界是有限的。实际上，假如break
point k存在，那么有</p>
<p><span class="math display">\[
m_{\mathcal{H}}(N) \leq B(N, k) \leq
\sum_{i=0}^{k-1}\left(\begin{array}{c}
N \\
i
\end{array}\right) \leq N^{k-1}
\]</span></p></li>
<li><p>其中B(N, k)就是break
point为k时增长函数的上界，可以发现增长函数上界的上界是多项式级别的(k-1次方)，那么增长函数最多是多项式级别，而VC界中的<span
class="math inline">\(\exp \left(-2 \epsilon^{2}
N\right)\)</span>是指数级别，显然VC界是存在的，有限的。</p></li>
<li><p>那么终于，对于break
point存在的情况，我们可以说泛化能力是有保证的，机器学习是有保证的。</p></li>
</ul>
<h1 id="vc维">VC维</h1>
<ul>
<li><p>VC界保证了学习的可行性，而VC维考虑的是假设空间的表达能力。前面说到增长函数是对于假设空间表达能力的一种衡量，两者也存在密切关联。</p></li>
<li><p>VC维定义为，给定假设空间H，其break
point存在，那么其VC维是能够打散的最大数据集的大小，即</p>
<p><span class="math display">\[
V C(\mathcal{H})=\max \left\{N: m_{\mathcal{H}}(N)=2^{N}\right\}
\]</span></p></li>
<li><p>回忆VC维定义中的两个概念：增长函数和打散。增长函数定义了假设空间解决对分的能力，打散代表着假设空间有能力解决一定量的数据集，对于每一种可能的对分都有对应假设，那么VC维就是从数据集的量来衡量假设空间的能力，假设空间越复杂，表达能力越强，就能打散更大的数据集，有足够多的假设解决更大数据集上的每一种上可能的对分——注意，不是每一种理论上可能的对分，因为VC维取的是能够达到的最大数据集容量，是存在而不是任意，即最大存在大小为VC维的数据集能够被该假设空间打散。</p></li>
<li><p>那么VC维具体是多少呢？其实之前我们定义过了，就是k-1，即容量小于break
point的数据集都能被打散，那么能被打散的数据集容量最大就是break point -
1</p></li>
<li><p>注意到这个k-1不就是VC界中增长函数上界中的多项式次数吗，因此VC界又可以写成：</p>
<p><span class="math display">\[
\forall g \in \mathcal{H}, \mathbb{P}\left[\left|E_{i n}(g)-E_{o u
t}(g)\right|&gt;\epsilon\right] \leq 4(2 N)^{V C(\mathcal{H})} \exp
\left(-\frac{1}{8} \epsilon^{2} N\right)
\]</span></p></li>
</ul>
<h1 id="衡量量化能力">衡量量化能力</h1>
<ul>
<li><p>由VC界的不等式可以看到，经验误差与泛化误差之间的差距（衡量泛化能力）和不等式右边即bad
case发生的概率相关联，假如我们给定了bad case发生的概率，设为：</p>
<p><span class="math display">\[
4(2 N)^{V C(\mathcal{H})} \exp \left(-\frac{1}{8} \epsilon^{2}
N\right)=\delta
\]</span></p>
<p>那么可以反过来算出衡量泛化能力的差距</p>
<p><span class="math display">\[
\epsilon=\sqrt{\frac{8}{N} \ln \left(\frac{4(2 N)^{V
C(\mathcal{H})}}{\delta}\right)}
\]</span></p></li>
<li><p>所以在机器学习基石和技法当中，老师经常写出一个VC
bound用来估计泛化误差的公式：</p>
<p><span class="math display">\[
E_{\text {out }}(\mathbf{w}) \leq E_{\text {in
}}(\mathbf{w})+\Omega(\mathcal{H})
\]</span></p></li>
<li><p>其中的<span
class="math inline">\(\Omega(\mathcal{H})\)</span>即<span
class="math inline">\(\sqrt{\frac{8}{N} \ln \left(\frac{4(2 N)^{V
C(\mathcal{H})}}{\delta}\right)}\)</span></p></li>
</ul>
<h1 id="参考">参考</h1>
<ul>
<li>https://zhuanlan.zhihu.com/p/59113933</li>
<li>https://www.coursera.org/learn/ntumlone-mathematicalfoundations</li>
</ul>
</div>
<script src="https://giscus.app/client.js"
        data-repo="thinkwee/thinkwee.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnk3OTYxNjMwOA=="
        data-category="Announcements"
        data-category-id="DIC_kwDOBL7ZNM4CkozI"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="en"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
              <a href="/tags/math/" rel="tag"># math</a>
              <a href="/tags/statistical-learning/" rel="tag"># statistical learning</a>
              <a href="/tags/vc-dimension/" rel="tag"># vc dimension</a>
          </div>

        
  <div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style">
    <a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a>
      <a class="a2a_button_facebook"></a>
      <a class="a2a_button_twitter"></a>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/04/05/graph-doc-thesis/" rel="prev" title="Notes for NLP with Graph-Structured Representations">
                  <i class="fa fa-angle-left"></i> Notes for NLP with Graph-Structured Representations
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/05/11/text-edit-generation/" rel="next" title="Edit-based Text Generation">
                  Edit-based Text Generation <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">ICP/IP地址/域名信息备案管理系统 </a>
      <img src="http://www.beian.gov.cn/img/new/gongan.png" alt=""><a href="https://beian.mps.gov.cn/#/query/webSearch?code=%E4%BA%ACICP%E5%A4%872023015408%E5%8F%B7" rel="noopener" target="_blank">京ICP备2023015408号 </a>
  </div>
  <div class="copyright">
    &copy; 2017 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Thinkwee</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">1.1m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">16:52</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/thinkwee" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.0/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>





  <script src="/js/third-party/addtoany.js"></script>

  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"g58NgfMJBlwTyftr6hizdozq-gzGzoHsz","app_key":"1nA1tNVxeeSlAumHogP0PvSd","server_url":null,"security":true}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://thinkwee.top/2020/05/15/vc-dimension/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
